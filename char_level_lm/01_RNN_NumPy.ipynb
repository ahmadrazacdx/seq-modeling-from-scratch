{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZ6tWgA1kICOV9wxvqGxB/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Character-Level Recurrent Neural Network Language Model**\n","\n","## **From Scratch Implementation in NumPy**\n","\n","This notebook implements a **vanilla RNN** for character-level language modeling, following the approach pioneered by Andrej Karpathy in his seminal blog post *\"The Unreasonable Effectiveness of Recurrent Neural Networks\"* (2015).\n","\n","\n","### **What We'll Build:**\n","- **Vanilla RNN** with tanh activation\n","- **Backpropagation Through Time (BPTT)** for gradient computation\n","- **Adam optimizer** for parameter updates\n","- **Character-level text generation** from learned patterns\n","---\n","*Notebook by*: Ahmad Raza [@ahmadrazacdx](https://github.com/ahmadrazacdx)<br>\n","*Date: 2025*  \n","*License: MIT*"],"metadata":{"id":"kv99qL16D9Kj"}},{"cell_type":"code","source":["import numpy as np\n","np.random.seed(42)"],"metadata":{"id":"SgSsJcK83DfA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### __DATA I/O__\n","We will use `Thirsty Crow` story as our small training data."],"metadata":{"id":"nbAO0JsH4o00"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"goJyoKz2zrmy","executionInfo":{"status":"ok","timestamp":1763524519341,"user_tz":-300,"elapsed":51,"user":{"displayName":"Ahmad Raza","userId":"04590257032587795730"}},"outputId":"95aa57b5-6c13-4b4c-c4d0-31da480f7ecc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data has 677 characters, 33 unique.\n"]}],"source":["#Load Data\n","data = open('../data/thirsty_crow.txt', 'r').read()\n","chars = sorted(list(set(data)))\n","data_size, vocab_size = len(data), len(chars)\n","print(f'Data has {data_size} characters, {vocab_size} unique.')"]},{"cell_type":"code","source":["char_to_ix = {ch:i for i,ch in enumerate(chars)}"],"metadata":{"id":"xc6oODzj3ijk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ix_to_char = {i:ch for i,ch in enumerate(chars)}"],"metadata":{"id":"ClysqC-_3wNq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Understanding the Mappings:**\n","- `char_to_ix`: Maps ```{'a': 0, 'b': 1, ..., 'z' → 25}``` etc.\n","- `ix_to_char`: Reverse mapping: ```{0: 'a', 1: 'b', ..., 25 → 'z'}```, etc.\n","\n","**Example:** The word \"cat\" becomes `[2, 0, 19]` if ```{'c' :2, 'a' :0, 't' :19}``` in our vocabulary."],"metadata":{"id":"Xod6Gp3EEnil"}},{"cell_type":"markdown","source":["### __HYPER-PARAMETERS__"],"metadata":{"id":"JhOzRBXz414W"}},{"cell_type":"code","source":["lr = 1e-3 # learning rate\n","seq_len = 25 # times RNN will be unrolled (Timesteps)\n","hidden_size= 100 # size of hidden units"],"metadata":{"id":"InWw7ZqC3xVO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hyperparameter Guide:**\n","\n","- **`lr` (learning rate)**: Step size for gradient descent\n","  - Too high → divergence, loss explodes\n","  - Too low → slow convergence\n","  - Adam typically: 1e-3 to 1e-4\n","  \n","- **`seq_len` (sequence length)**: Number of characters processed at once\n","  - Longer → captures more context, but harder to train (vanishing gradients)\n","  - Typical range: 20-50 for character-level models\n","  \n","- **`hidden_size`**: Model capacity (memory)\n","  - Larger → more expressive, but risk of overfitting\n","  - Karpathy used 100-512 for various tasks\n","  - Rule of thumb: Start with 100, increase if underfitting"],"metadata":{"id":"ST1QGIjoFVn9"}},{"cell_type":"markdown","source":["### __MODEL PARAM INIT__\n","**Initializing weight matrices for the RNN.**\n","\n","- $\\mathbf{W}_{xh} \\in \\mathbb{R}^{H \\times V}$ Input-to-hidden weights\n","- $\\mathbf{W}_{hh} \\in \\mathbb{R}^{H \\times H}$ Hidden-to-hidden (recurrent) weights\n","- $\\mathbf{W}_{hy} \\in \\mathbb{R}^{V \\times H}$ Hidden-to-output weights\n","- $\\mathbf{b}_h \\in \\mathbb{R}^{H \\times 1}$ Hidden bias\n","- $\\mathbf{b}_y \\in \\mathbb{R}^{V \\times 1}$ Output bias\n","\n","**Where:**  \n","- $H$ = hidden size  \n","- $V$ = vocabulary size"],"metadata":{"id":"5LRNhINY6CMp"}},{"cell_type":"code","source":["Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden (H, V)\n","Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden (H, H)\n","Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output (V, H)\n","bh = np.zeros((hidden_size, 1)) # hidden bias (H, 1)\n","by = np.zeros((vocab_size, 1)) # output bias (V, 1)"],"metadata":{"id":"NPbbN7zi5jjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"\"\"\n","Wxh: Input to hidden  : {Wxh.shape}\n","Whh: Hidden to hidden : {Whh.shape}\n","Why: Hidden to output : {Why.shape}\n","bh: Hidden bias       : {bh.shape}\n","by: Output bias       : {by.shape}\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HGbspWj7RRE","executionInfo":{"status":"ok","timestamp":1763524522494,"user_tz":-300,"elapsed":234,"user":{"displayName":"Ahmad Raza","userId":"04590257032587795730"}},"outputId":"3ff61a2d-9cae-4e3e-f652-2413f8bef27e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Wxh: Input to hidden  : (100, 33)\n","Whh: Hidden to hidden : (100, 100)\n","Why: Hidden to output : (33, 100)\n","bh: Hidden bias       : (100, 1)\n","by: Output bias       : (33, 1)\n","\n"]}]},{"cell_type":"markdown","source":["### __ADAM OPTIMIZER INITIALIZATION__\n","\n","**Adam** (Adaptive Moment Estimation) is a modern optimizer that adapts learning rates for each parameter.\n","\n","**Reference:** Kingma & Ba (2014) - *Adam: A Method for Stochastic Optimization*"],"metadata":{"id":"xvWhMsGbeRjl"}},{"cell_type":"code","source":["# Adam hyperparameters\n","beta1 = 0.9\n","beta2 = 0.999\n","epsilon = 1e-8\n","\n","# Adam memory variables (first moment - momentum)\n","mWxh = np.zeros_like(Wxh)\n","mWhh = np.zeros_like(Whh)\n","mWhy = np.zeros_like(Why)\n","mbh = np.zeros_like(bh)\n","mby = np.zeros_like(by)\n","\n","# Adam memory variables (second moment - RMSprop)\n","vWxh = np.zeros_like(Wxh)\n","vWhh = np.zeros_like(Whh)\n","vWhy = np.zeros_like(Why)\n","vbh = np.zeros_like(bh)\n","vby = np.zeros_like(by)\n","\n","# Timestep counter for bias correction\n","t_adam = 0"],"metadata":{"id":"tUZFfUeAePrY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What are these variables?**\n","\n","- **`m*` (first moment)**: Running average of gradients → provides momentum\n","  - Helps accelerate convergence in relevant directions\n","  - Reduces oscillations\n","  \n","- **`v*` (second moment)**: Running average of squared gradients → adaptive learning rates\n","  - Automatically scales learning rate for each parameter\n","  - Large gradients → smaller effective learning rate\n","  - Small gradients → larger effective learning rate\n","  \n","- **`t_adam`**: Iteration counter for bias correction\n","  - Early in training, m and v are biased toward zero\n","  - Correction: $\\hat{m}_t = m_t / (1 - \\beta_1^t)$, $\\hat{v}_t = v_t / (1 - \\beta_2^t)$"],"metadata":{"id":"ppXFkYkxHJgF"}},{"cell_type":"markdown","source":["### __SINGLE VANILLA RNN CELL__\n","\n","**Forward pass equations:**\n","\n","$$\n","\\begin{align}\n","\\mathbf{z}_t &= \\mathbf{W}_{xh} \\mathbf{x}_t + \\mathbf{W}_{hh} \\mathbf{h}_{t-1} + \\mathbf{b}_h \\quad &\\text{(pre-activation)} \\\\\n","\\mathbf{h}_t &= \\tanh(\\mathbf{z}_t) \\quad &\\text{(hidden state)} \\\\\n","\\mathbf{y}_t &= \\mathbf{W}_{hy} \\mathbf{h}_t + \\mathbf{b}_y \\quad &\\text{(output logits)}\n","\\end{align}\n","$$\n","\n","**Reference:** Elman (1990) - *Finding Structure in Time*"],"metadata":{"id":"VkDtomuF8LFZ"}},{"cell_type":"code","source":["def rnn(x_prev, h_prev):\n","    \"\"\"\n","    Single RNN cell with embedding lookup\n","\n","    Inputs:\n","        - x_prev: Previous input character (one-hot vector)\n","        - h_prev: Previous hidden state (H,1)\n","\n","    Returns:\n","        - ht: Current hidden state (H, 1)\n","        - yt: Output logits (V, 1)\\\n","    \"\"\"\n","    zt = np.dot(Wxh, x_prev) + np.dot(Whh, h_prev) + bh\n","    # (H,V) @ (V,1) -> (H,1) + (H,1) <- (H,H) @ (H,1) + (H,1) = (H,1)\n","    ht = np.tanh(zt) # (H,1)\n","    yt = np.dot(Why, ht) + by # (V,H)@(H,1) -> (V,1) + (V,1) = (V,1)\n","    return ht, yt"],"metadata":{"id":"AVvRr4GJ7SmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Understanding the RNN Cell:**\n","\n","**What's happening here?**\n","- At each timestep $t$, the RNN takes two inputs:\n","  1. Current character $\\mathbf{x}_t$ (one-hot vector)\n","  2. Previous memory $\\mathbf{h}_{t-1}$ (hidden state from last step)\n","  \n","- It outputs:\n","  1. New memory $\\mathbf{h}_t$ (encodes everything seen so far)\n","  2. Prediction $\\mathbf{y}_t$ (logits for next character)\n","\n","**The \"recurrent\" part:** $\\mathbf{h}_t$ depends on $\\mathbf{h}_{t-1}$, creating a feedback loop through time."],"metadata":{"id":"4f5wu1Tj9rbm"}},{"cell_type":"markdown","source":["### __FORWARD PASS__\n"],"metadata":{"id":"JSiqg1u1Fcuo"}},{"cell_type":"code","source":["def forward(inputs, targets, h_prev):\n","    \"\"\"\n","    Forward pass through unrolled RNN\n","\n","    Inputs:\n","        - inputs: List of character indices, e.g., [5, 8, 12, 12, 15] for \"hello\"\n","        - targets: List of target character indices (inputs shifted by 1)\n","        - h_prev: Initial hidden state from previous sequence, shape (H, 1)\n","\n","    Returns:\n","        - xt: Dict of one-hot inputs {0: x_0, 1: x_1, ...}\n","        - ht: Dict of hidden states {-1: h_init, 0: h_0, 1: h_1, ...}\n","        - yt: Dict of output logits {0: y_0, 1: y_1, ...}\n","        - probt: Dict of probability distributions {0: p_0, 1: p_1, ...}\n","        - loss: Total cross-entropy loss across all timesteps (scalar)\n","    \"\"\"\n","    # Initialize storage dictionaries\n","    xt = {}  # Store one-hot encoded inputs\n","    ht = {}  # Store hidden states\n","    yt = {}  # Store raw outputs (before softmax)\n","    probt = {}  # Store probability distributions (after softmax)\n","\n","    # Set initial hidden state\n","    ht[-1] = np.copy(h_prev) #(H,1)\n","    loss = 0\n","    # Loop through each timestep in the sequence\n","    for t in range(len(inputs)):\n","        # Step 1: Convert character index to one-hot vector\n","        xt[t] = np.zeros((vocab_size, 1)) #(V,1)\n","        xt[t][inputs[t]] = 1  # Set the position of char to 1, (V,1)\n","\n","        # Step 2: Run RNN cell (forward computation)\n","        ht[t], yt[t] = rnn(xt[t], ht[t-1]) # (H,1), (V,1)\n","\n","        # Step 3: Apply softmax to get probabilities (Subtract max for stability)\n","        exp_scores = np.exp(yt[t] - np.max(yt[t])) # (V,1)\n","        probt[t] = exp_scores / np.sum(exp_scores) # (V,1)\n","\n","        # Step 4: Compute loss for this timestep\n","        # Cross-entropy: -log(probability of correct next character)\n","        loss += -np.log(probt[t][targets[t], 0]+ epsilon)\n","    return xt, ht, probt, loss"],"metadata":{"id":"ErpAgrEEEpld"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Deep Dive: Understanding the Forward Pass**\n","\n","**1. Why one-hot encoding?**\n","```python\n","# If vocab = ['a', 'b', 'c', ..., 'z'] and char_to_ix = {'a':0, 'b':1, ...}\n","# Character 'c' (index 2) becomes:\n","xt[t] = [0, 0, 1, 0, 0, ..., 0]  # 1 at position 2, zeros elsewhere\n","```\n","\n","**2. Cross-Entropy Loss Formula**\n","\n","$$\\mathcal{L}_t = -\\log p_t[y^*_t]$$\n","\n","Where:\n","- $p_t$: Probability distribution at time $t$ (output of softmax)\n","\n","- $y^*_t$: Correct next character (target)\n","- Lower loss → model assigns higher probability to correct character\n","\n","**Total loss:** $\\mathcal{L} = \\sum_{t=0}^{T-1} \\mathcal{L}_t$\n","\n","**3. Why maintain hidden state?**\n","\n","The hidden state $\\mathbf{h}_t$ acts as the network's \"memory\":\n","- Encodes information about all characters seen so far\n","- Enables the model to learn long-term dependencies\n","- Without it, predictions would be independent at each position!\n","\n","**Example:** To predict the next word in \"The cat sat on the ___\", the model needs to remember \"cat\" from earlier in the sequence."],"metadata":{"id":"WnY_dRbDIWDs"}},{"cell_type":"markdown","source":["### __BACKWARD PASS__\n","**Complete BPTT Equations (As Implemented Below In Code):**\n","\n","**Step 1: Output Gradient (Softmax + Cross-Entropy)**\n","$$\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} = \\mathbf{p}_t - \\mathbf{1}_{y^*_t}$$\n","\n","**Step 2: Output Weight Gradients**\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{hy}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\mathbf{h}_t^T, \\quad \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_y} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t}$$\n","\n","**Step 3: Hidden State Gradient (Two Sources!)**\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} = \\mathbf{W}_{hy}^T \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{t+1}}$$\n","\n","**Step 4: Pre-Activation Gradient (Tanh)**\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} \\odot (1 - \\mathbf{h}_t^2)$$\n","**Step 5: Hidden Weight Gradients (Accumulated)**\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{xh}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_t} \\mathbf{x}_t^T, \\quad \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{hh}} = \\sum_{t=0}^{T-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_t} \\mathbf{h}_{t-1}^T$$\n","**Step 6: Gradient to Previous Timestep**\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{t-1}} = \\mathbf{W}_{hh}^T \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_t}$$\n","**Visual:** Gradients flow backward from $t=T-1 \\rightarrow 0$, accumulating contributions from all timesteps."],"metadata":{"id":"7CTgWopPOAka"}},{"cell_type":"code","source":["def backward(inputs, targets, xt, ht, probt):\n","    \"\"\"\n","    Backpropagation Through Time (BPTT)\n","\n","    Inputs:\n","        - inputs: List of input character indices\n","        - targets: List of target character indices\n","        - xt: Dict of one-hot inputs from forward pass\n","        - ht: Dict of hidden states from forward pass\n","        - probt: Dict of probability distributions from forward pass\n","\n","    Returns:\n","        - dWxh: Gradient w.r.t. input-to-hidden weights, shape (H, V)\n","        - dWhh: Gradient w.r.t. hidden-to-hidden weights, shape (H, H)\n","        - dWhy: Gradient w.r.t. hidden-to-output weights, shape (V, H)\n","        - dbh: Gradient w.r.t. hidden bias, shape (H, 1)\n","        - dby: Gradient w.r.t. output bias, shape (V, 1)\n","    \"\"\"\n","\n","    # Initialize gradients to zero\n","    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n","    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n","\n","    # Gradient of hidden state at next timestep (initially zero)\n","    dh_next = np.zeros_like(ht[0]) # (H,1)\n","\n","    # Backpropagate through time (from last to first timestep)\n","    for t in reversed(range(len(inputs))):\n","        # Step 1: Gradient of loss w.r.t output probabilities\n","        dy = np.copy(probt[t]) #(V,1)\n","        dy[targets[t]] -= 1  # Subtract 1 from correct class (cross-entropy gradient), dy[correct_class] = dy[correct_class] - 1, (V,1)\n","\n","        # Step 2: Gradients for output layer (Why, by)\n","        dWhy += np.dot(dy, ht[t].T) # (V,1)@(H,1)-> (1,H) = (V,H)\n","        dby += dy # (V,1)\n","\n","        # Step 3: Gradient w.r.t hidden state\n","        # Comes from two sources: current output and next timestep\n","        dh = np.dot(Why.T, dy) + dh_next # (V,H)-> (H,V)@(V,1)=(H,1)+(H,1)=(H,1)\n","\n","        # Step 4: Gradient through tanh activation\n","        dzt = (1 - ht[t]**2) * dh  #(H,1)*(H,1)=(H,1)\n","\n","        # Step 5: Gradients for hidden layer (Wxh, Whh, bh)\n","        dWxh += np.dot(dzt, xt[t].T) #(H,1)@(V,1)->(1,V)=(H,V)\n","        dWhh += np.dot(dzt, ht[t-1].T) #(H,1)@(H,1)->(1,H)=H,H\n","        dbh += dzt #(H,1)\n","\n","        # Step 6: Pass gradient to previous timestep\n","        dh_next = np.dot(Whh.T, dzt) #(H,H)@(H,1)=(H,1)\n","\n","    # Clip gradients to prevent exploding gradients\n","    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n","        np.clip(dparam, -5, 5, out=dparam)\n","\n","    return dWxh, dWhh, dWhy, dbh, dby"],"metadata":{"id":"uX93liyrK-as"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Understanding BPTT: The Gradient Flow**\n","\n","**1. The Softmax-CrossEntropy Gradient**\n","\n","For softmax activation with cross-entropy loss, the gradient simplifies to:\n","\n","$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} = \\mathbf{p} - \\mathbf{1}_{y^*}$$\n","\n","Where $\\mathbf{1}_{y^*}$ is the one-hot vector of the target.\n","\n","**Example:** If vocab_size=5 and target=2:\n","```python\n","probt[t] = [0.1, 0.2, 0.6, 0.05, 0.05]  # Model's prediction\n","target = 2  # Correct class\n","dy = [0.1, 0.2, -0.4, 0.05, 0.05]  # Gradient (0.6 - 1 = -0.4 at position 2)\n","```\n","\n","**2. Why Gradient Clipping?**\n","\n","RNNs suffer from **exploding gradients** because:\n","- Gradients are multiplied by $\\mathbf{W}_{hh}$ at each timestep\n","- Over many timesteps: $(\\mathbf{W}_{hh})^T \\cdot (\\mathbf{W}_{hh})^T \\cdot ... \\cdot (\\mathbf{W}_{hh})^T$\n","- If largest eigenvalue of $\\mathbf{W}_{hh}$ > 1 → exponential growth\n","- Clipping prevents: `loss = nan`, `weights = inf`\n","\n","**3. Gradient Accumulation**\n","\n","Notice `+=` instead of `=`:\n","```python\n","dWxh += np.dot(dzt, xt[t].T)  # Accumulate across timesteps\n","```\n","We sum gradients from all timesteps because the same weights are shared across time!\n","\n","**4. Tanh Derivative: Why (1 - h²)?**\n","$$\\therefore h_t = tanh(z)$$\n","$$\\frac{d}{dz}\\tanh(z) = 1 - \\tanh^2(z) = 1 - h^2$$\n","\n","**Vanishing Gradient Problem:** When $|h_t| \\approx 1$, derivative $\\approx 0$ → gradients vanish.\n","This is why LSTMs/GRUs were invented!"],"metadata":{"id":"Spgg8FYXLqKl"}},{"cell_type":"markdown","source":["### __UPDATE PARAMS WITH ADAM__"],"metadata":{"id":"whAHx2WTW03k"}},{"cell_type":"code","source":["def update_parameters(dWxh, dWhh, dWhy, dbh, dby, learning_rate):\n","    \"\"\"\n","    Update model parameters using Adam optimizer\n","\n","    Inputs:\n","        - dWxh: Gradient for input-to-hidden weights (H, V)\n","        - dWhh: Gradient for hidden-to-hidden weights (H, H)\n","        - dWhy: Gradient for hidden-to-output weights (V, H)\n","        - dbh: Gradient for hidden bias (H, 1)\n","        - dby: Gradient for output bias (V, 1)\n","        - learning_rate: Step size for parameter updates\n","\n","    Returns:\n","        - None (updates global parameters in-place)\n","    \"\"\"\n","    global Wxh, Whh, Why, bh, by\n","    global mWxh, mWhh, mWhy, mbh, mby\n","    global vWxh, vWhh, vWhy, vbh, vby\n","    global t_adam\n","\n","    # Increment timestep\n","    t_adam += 1\n","\n","    # Update Wxh\n","    mWxh = beta1 * mWxh + (1 - beta1) * dWxh\n","    vWxh = beta2 * vWxh + (1 - beta2) * (dWxh ** 2)\n","    mWxh_corrected = mWxh / (1 - beta1 ** t_adam)\n","    vWxh_corrected = vWxh / (1 - beta2 ** t_adam)\n","    Wxh -= learning_rate * mWxh_corrected / (np.sqrt(vWxh_corrected) + epsilon)\n","\n","    # Update Whh\n","    mWhh = beta1 * mWhh + (1 - beta1) * dWhh\n","    vWhh = beta2 * vWhh + (1 - beta2) * (dWhh ** 2)\n","    mWhh_corrected = mWhh / (1 - beta1 ** t_adam)\n","    vWhh_corrected = vWhh / (1 - beta2 ** t_adam)\n","    Whh -= learning_rate * mWhh_corrected / (np.sqrt(vWhh_corrected) + epsilon)\n","\n","    # Update Why\n","    mWhy = beta1 * mWhy + (1 - beta1) * dWhy\n","    vWhy = beta2 * vWhy + (1 - beta2) * (dWhy ** 2)\n","    mWhy_corrected = mWhy / (1 - beta1 ** t_adam)\n","    vWhy_corrected = vWhy / (1 - beta2 ** t_adam)\n","    Why -= learning_rate * mWhy_corrected / (np.sqrt(vWhy_corrected) + epsilon)\n","\n","    # Update bh\n","    mbh = beta1 * mbh + (1 - beta1) * dbh\n","    vbh = beta2 * vbh + (1 - beta2) * (dbh ** 2)\n","    mbh_corrected = mbh / (1 - beta1 ** t_adam)\n","    vbh_corrected = vbh / (1 - beta2 ** t_adam)\n","    bh -= learning_rate * mbh_corrected / (np.sqrt(vbh_corrected) + epsilon)\n","\n","    # Update by\n","    mby = beta1 * mby + (1 - beta1) * dby\n","    vby = beta2 * vby + (1 - beta2) * (dby ** 2)\n","    mby_corrected = mby / (1 - beta1 ** t_adam)\n","    vby_corrected = vby / (1 - beta2 ** t_adam)\n","    by -= learning_rate * mby_corrected / (np.sqrt(vby_corrected) + epsilon)"],"metadata":{"id":"b5aaGQ1ELBbx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### __TRAIN MODEL__\n"],"metadata":{"id":"hpHLQqh7XFil"}},{"cell_type":"code","source":["def train(data, num_iterations=1000, print_every=100, sample_every=100):\n","    \"\"\"\n","    Train RNN language model using Adam optimizer\n","\n","    Inputs:\n","        - data: String of training text\n","        - num_iterations: Number of training iterations (not full data passes)\n","        - print_every: Print loss every N iterations\n","        - sample_every: Generate sample text every N iterations\n","\n","    Returns:\n","        - smooth_loss: Exponentially smoothed loss value\n","\n","    Note: Hidden state h_prev is maintained across sequences for temporal continuity.\n","        Only reset when reaching end of data or on first iteration.\n","    \"\"\"\n","    sequences_per_epoch = len(data) // seq_len\n","    smooth_loss = -np.log(1.0 / vocab_size) * seq_len\n","    n = 0  # Iteration counter\n","    p = 0  # Data pointer (position in text)\n","    h_prev = np.zeros((hidden_size, 1))\n","\n","    while n < num_iterations:\n","        # Reset pointer and hidden state at end of data or first iteration\n","        if p + seq_len + 1 >= len(data) or n == 0:\n","            h_prev = np.zeros((hidden_size, 1))  # Fresh start\n","            p = 0  # Go back to beginning\n","\n","        # Input:  characters at positions [p, p+1, ..., p+seq_len-1]\n","        # Target: characters at positions [p+1, p+2, ..., p+seq_len]\n","        inputs = [char_to_ix[ch] for ch in data[p:p+seq_len]]\n","        targets = [char_to_ix[ch] for ch in data[p+1:p+seq_len+1]]\n","        # Forward pass (pass hidden state!)\n","        xt, ht, probt, loss = forward(inputs, targets, h_prev)\n","        # Update hidden state for next sequence\n","        h_prev = np.copy(ht[len(inputs) - 1])\n","        # Backward pass\n","        dWxh, dWhh, dWhy, dbh, dby = backward(inputs, targets,xt, ht, probt)\n","        # Update parameters\n","        update_parameters(dWxh, dWhh, dWhy, dbh, dby, lr)\n","        # Update smooth loss\n","        smooth_loss = smooth_loss * 0.999 + loss * 0.001\n","        # Print progress\n","        if n % print_every == 0:\n","            print(f\"Iter {n:6d} | Loss: {smooth_loss:.4f}\")\n","        # Generate sample text\n","        if n % sample_every == 0 and n > 0:\n","            print(f\"\\n{'='*60}\")\n","            print(f\"SAMPLE at iteration {n}:\")\n","            print(f\"{'='*60}\")\n","            sample_text = sample(data[0], n_chars=200)\n","            print(sample_text)\n","            print(f\"{'='*60}\\n\")\n","        p += seq_len\n","        n += 1\n","\n","    print(\"\\nTraining complete!\")\n","    return smooth_loss"],"metadata":{"id":"HvrBIPp3XAt-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Deep Dive: What's Really Happening?**\n","\n","**The Training Loop Flow:**\n","\n","```\n","Initialize: h = zeros(100, 1)\n","\n","Iteration 1:\n","  Data: \"Once upon a time, on a ve\"\n","  → Forward: Get loss, store states\n","  → h_prev = h[24]  ← Keep this for next iteration!\n","  → Backward: Compute gradients\n","  → Adam: Update weights\n","\n","Iteration 2:\n","  Data: \"ry hot day, a thirsty cro\"\n","  → Forward with h_prev from iteration 1  ← CONTINUITY!\n","  → ...\n","```\n","\n","**Why This Works:**\n","\n","1. **Hidden state continuity** lets the model learn long-range dependencies across sequence boundaries\n","2. **Sliding window** ensures we see all the data\n","3. **Adam optimizer** adapts learning rates automatically\n","4. **Gradient clipping** prevents explosion\n","5. **Smooth loss** gives us a stable metric to monitor\n","\n","**Common Pitfall:** Resetting hidden state too frequently breaks temporal learning!"],"metadata":{"id":"xqbJ8Rh_MljU"}},{"cell_type":"markdown","source":["### __SAMPLING FUNCTION (GENERATE TEXT)__"],"metadata":{"id":"j4GOFoOuYzvD"}},{"cell_type":"code","source":["def sample(seed_char, n_chars=100):\n","    \"\"\"\n","    Generate text by sampling from the trained RNN language model\n","\n","    Inputs:\n","        - seed_char: Starting character for text generation\n","        - n_chars: Number of characters to generate (default 100)\n","\n","    Returns:\n","        - String of generated text starting with seed_char\n","\n","    Note: Uses stochastic sampling from probability distribution (not argmax).\n","          Numerically stable softmax implementation with max subtraction.\n","    \"\"\"\n","    if seed_char not in char_to_ix:\n","        if seed_char.lower() in char_to_ix:\n","            seed_char = seed_char.lower()\n","        else:\n","            seed_char = data[0]\n","            print(f\"Warning: Seed not in vocab. Using '{seed_char}' instead\")\n","\n","    x = np.zeros((vocab_size, 1)) # Convert seed character to index\n","    x[char_to_ix[seed_char]] = 1\n","    h = np.zeros((hidden_size, 1)) # Initialize hidden state\n","    generated_chars = [seed_char] # Store generated characters\n","\n","    for _ in range(n_chars):\n","        h, y = rnn(x, h)\n","        p = np.exp(y - np.max(y)) / np.sum(np.exp(y - np.max(y)))\n","        ix = np.random.choice(range(vocab_size), p=p.ravel())\n","        char = ix_to_char[ix]\n","        generated_chars.append(char)\n","        x = np.zeros((vocab_size, 1))\n","        x[ix] = 1\n","\n","    return ''.join(generated_chars)"],"metadata":{"id":"ldl7q4JsYWJs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Understanding Text Generation**\n","\n","**Example:** Suppose after \"Once upon a t\", the model outputs probabilities:\n","\n","```python\n","Characters: ['a', 'h', 'i', 'm', 'o', ...]\n","Probabilities: [0.02, 0.65, 0.25, 0.05, 0.01, ...]\n","```\n","\n","**Greedy Decoding (argmax):** Always pick 'h' → \"Once upon a th\" → then always 'e' → \"Once upon a the the the...\" based on character with highest probability each time.\n","\n","**Sampling:**\n","- 65% chance pick 'h' → \"Once upon a time\"\n","- 25% chance pick 'i' → \"Once upon a time\"  \n","- 5% chance pick 'm' → \"Once upon a time\"\n","- ...more diverse output!\n","\n","**Why Fresh Hidden State?**\n","When generating, we start with `h = zeros()` because:\n","1. We're creating NEW text, not continuing training data\n","2. Starting fresh avoids bias from training sequences\n","3. The model will build up context as it generates\n","\n","**Quality:**\n","- Early in training: Gibberish (\"xqz kpt uwm...\")\n","- Mid training: Recognizable patterns (\"the cat wat on...\")\n","- Late training: Coherent text (\"the cat sat on the mat\")"],"metadata":{"id":"lADZxKmeNAXE"}},{"cell_type":"markdown","source":["### __RUN TRAINING__"],"metadata":{"id":"1y0M3vMIZcjn"}},{"cell_type":"code","source":["final_loss = train(data, num_iterations=50000, print_every=1000, sample_every=5000)\n","print(f\"\\nFinal smooth loss: {final_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjfsldMiZVna","executionInfo":{"status":"ok","timestamp":1763524650227,"user_tz":-300,"elapsed":125381,"user":{"displayName":"Ahmad Raza","userId":"04590257032587795730"}},"outputId":"b034a976-ff2c-494f-96dc-3071981b5756"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iter      0 | Loss: 87.4127\n","Iter   1000 | Loss: 68.4298\n","Iter   2000 | Loss: 40.6549\n","Iter   3000 | Loss: 19.9702\n","Iter   4000 | Loss: 10.4223\n","Iter   5000 | Loss: 4.5660\n","\n","============================================================\n","SAMPLE at iteration 5000:\n","============================================================\n","Once upon a time, on a very hot day he tot ane. The crow tho pily, cow sinkint y aag hed ily, crong and flowd inen on ide\n","!ThH criagly he water.\n","He felt refreap h  aly, a thel hd tte wasea hited ade. T\n","============================================================\n","\n","Iter   6000 | Loss: 3.6948\n","Iter   7000 | Loss: 1.6394\n","Iter   8000 | Loss: 0.7420\n","Iter   9000 | Loss: 0.3549\n","Iter  10000 | Loss: 2.0044\n","\n","============================================================\n","SAMPLE at iteration 10000:\n","============================================================\n","Once upon a time, on a very hot dry, a tome huthide.\n","\n","Aftea pith, crow was feeling tired and weak.\n","\n","After flting for a long time, the crow finally saw a pitcher lying under a tree. He quickly flew dofl\n","============================================================\n","\n","Iter  11000 | Loss: 0.8710\n","Iter  12000 | Loss: 0.3947\n","Iter  13000 | Loss: 0.1915\n","Iter  14000 | Loss: 0.0995\n","Iter  15000 | Loss: 0.0545\n","\n","============================================================\n","SAMPLE at iteration 15000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  16000 | Loss: 2.2809\n","Iter  17000 | Loss: 0.9284\n","Iter  18000 | Loss: 0.3872\n","Iter  19000 | Loss: 0.1702\n","Iter  20000 | Loss: 0.0803\n","\n","============================================================\n","SAMPLE at iteration 20000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and woak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  21000 | Loss: 0.0410\n","Iter  22000 | Loss: 0.0225\n","Iter  23000 | Loss: 0.0131\n","Iter  24000 | Loss: 0.0080\n","Iter  25000 | Loss: 3.0909\n","\n","============================================================\n","SAMPLE at iteration 25000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in aely pot dase, and woakly Tow w augh  fowas nr a lotllspfle lyigg up stored cntid ahe flew dist, the crow could drink the water.\n","He fel\n","============================================================\n","\n","Iter  26000 | Loss: 1.2114\n","Iter  27000 | Loss: 0.4788\n","Iter  28000 | Loss: 0.1953\n","Iter  29000 | Loss: 0.0840\n","Iter  30000 | Loss: 0.0388\n","\n","============================================================\n","SAMPLE at iteration 30000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  31000 | Loss: 0.0195\n","Iter  32000 | Loss: 0.0107\n","Iter  33000 | Loss: 0.0063\n","Iter  34000 | Loss: 0.0039\n","Iter  35000 | Loss: 2.1626\n","\n","============================================================\n","SAMPLE at iteration 35000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  36000 | Loss: 0.8376\n","Iter  37000 | Loss: 0.3296\n","Iter  38000 | Loss: 0.1342\n","Iter  39000 | Loss: 0.0576\n","Iter  40000 | Loss: 0.0267\n","\n","============================================================\n","SAMPLE at iteration 40000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  41000 | Loss: 0.0136\n","Iter  42000 | Loss: 0.0075\n","Iter  43000 | Loss: 0.0045\n","Iter  44000 | Loss: 0.0028\n","Iter  45000 | Loss: 0.0018\n","\n","============================================================\n","SAMPLE at iteration 45000:\n","============================================================\n","Once upon a time, on a very hot day, a thirsty crow was flying in search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a long time, the crow fi\n","============================================================\n","\n","Iter  46000 | Loss: 0.0012\n","Iter  47000 | Loss: 1.4914\n","Iter  48000 | Loss: 0.5745\n","Iter  49000 | Loss: 0.2253\n","\n","Training complete!\n","\n","Final smooth loss: 0.0917\n"]}]},{"cell_type":"markdown","source":["### __TEST DIFFERENT SEEDS__"],"metadata":{"id":"jhx3NWCEtl0J"}},{"cell_type":"code","source":["seed_chars = ['T', 'A', 'H', 'W', 'I']\n","for char in seed_chars:\n","    generated = sample(char, n_chars=150)\n","    print(char, ':', generated)\n","    print(\"-\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_1JWyvyZi7B","executionInfo":{"status":"ok","timestamp":1763524650261,"user_tz":-300,"elapsed":24,"user":{"displayName":"Ahmad Raza","userId":"04590257032587795730"}},"outputId":"0ddf467b-cc64-4863-e366-3ceaba2fadeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["T : Thed ret leoked until the water came up high enough.\n","\n","At last, the crow could drink the water.\n","He felt refreshed and flew away happily he flew down and\n","------------------------------------------------------------\n","A : At lying inssea.\n","\n","\n","\n","gtw a lying un search of water. The sun was shining brightly, and the poor crow was feeling tired and weak.\n","\n","After flying for a lon\n","------------------------------------------------------------\n","H : He water at the bottom, but his beak could not reach it.\n","\n","The crow thought for a moment. Then he got an idea!\n","\n","He started picking up small pebbles one \n","------------------------------------------------------------\n","W : was shonished and flew away happily he by tte was a lowt anch the bottom, but his beak could not reach it.\n","\n","The crow thought for a moment. Then he got \n","------------------------------------------------------------\n","I : ing up small pebbles one by one and dropped them into the pitcher. Slowly, the water began to rise. The crow continued dropping stones until the water \n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## **SUMMARY**\n","### **Key Takeaways:**\n","1. **Hidden State = Memory**: The hidden state $\\mathbf{h}_t$ encodes all information seen so far\n","2. **BPTT = Unrolled Backprop**: Treat RNN as deep feedforward network, backprop through time for all timestamps\n","3. **Gradient Clipping is Essential**: RNNs suffer from exploding/vanishing gradients\n","4. **Hidden State Continuity Matters**: Maintaining $\\mathbf{h}_t$ across sequences enables long-range learning\n","5. **Sampling > Greedy Encoding**: Introduces diversity in generation\n","### **Limitations of Vanilla RNNs:**\n","- **Vanishing Gradients**: Can't learn very long-range dependencies (>20-30 timesteps)  \n","- **Slow Training**: Sequential nature prevents parallelization  \n","- **Limited Memory**: Fixed-size hidden state bottleneck  \n","### **Modern Improvements:**\n","- **LSTMs (Long Short-Term Memory)**: Solve vanishing gradient with gating mechanisms  \n","- **GRUs (Gated Recurrent Units)**: Simpler than LSTM, similar performance\n","- **Transformers**: Use attention, fully parallelizable, now dominant in NLP\n","### **References:**\n","1. Karpathy, A. (2015). *The Unreasonable Effectiveness of RNNs*. [Blog Post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n","2. Elman, J. (1990). *Finding Structure in Time*. Cognitive Science, 14(2), 179-211.\n","3. Rumelhart, D. E., et al. (1986). *Learning representations by back-propagating errors*. Nature, 323(6088), 533-536.\n","4. Kingma, D. P., & Ba, J. (2014). *Adam: A Method for Stochastic Optimization*. arXiv:1412.6980.\n","### **Further Reading:**\n","1. Karpathy, A. (2015). [The Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n","2. Hochreiter & Schmidhuber (1997). Long Short-Term Memory. Neural Computation.\n","3. Cho et al. (2014). Learning Phrase Representations using RNN Encoder-Decoder for SMT.\n","4. Vaswani et al. (2017). Attention Is All You Need. NeurIPS.\n","5. Goodfellow et al. (2016). Deep Learning. Chapter 10: Sequence Modeling."],"metadata":{"id":"yWmqjNEnEaB4"}}]}