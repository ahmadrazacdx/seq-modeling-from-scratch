{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Seq2Seq with Bahdanau Attention**\n",
        "\n",
        "## **From Scratch Implementation in NumPy**\n",
        "\n",
        "This notebook builds upon the standard Encoder-Decoder architecture by implementing **Bahdanau (Additive) Attention** [Bahdanau et al., 2014].\n",
        "\n",
        "### **Why Attention?**\n",
        "In a standard Encoder-Decoder, the Encoder must compress the entire source sentence into a single fixed-size vector (the \"bottleneck\"). This causes performance to degrade as sentences get longer.\n",
        "\n",
        "**Attention** solves this by allowing the Decoder to \"look back\" at the entire sequence of Encoder hidden states. At every step of generation, the model calculates a **dynamic context vector** that focuses on the most relevant parts of the input.\n",
        "\n",
        "### **Architecture Changes:**\n",
        "1.  **Encoder:** Returns all hidden states $H = \\{h_1, \\dots, h_T\\}$, not just the last one.\n",
        "2.  **Attention Mechanism:** A small neural network that computes \"Energy Scores\" between the Decoder's previous state and every Encoder state.\n",
        "3.  **Decoder:** Receives a concatenated input $[y_{t-1}; c_t]$ (Word Embedding + Context Vector).\n",
        "\n",
        "---\n",
        "*Notebook by*: Ahmad Raza [@ahmadrazacdx](https://github.com/ahmadrazacdx)<br>\n",
        "*Date: 2025* <br>\n",
        "*License: MIT*"
      ],
      "metadata": {
        "id": "9bhi1NwuXB6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "SgSsJcK83DfA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goJyoKz2zrmy",
        "outputId": "1be69d30-2e06-4818-b9db-90c672b829fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 37 sentences.\n",
            "Example sentences: ['the crow was thirsty .', 'a bird was very dry .']\n"
          ]
        }
      ],
      "source": [
        "data = open('../data/thirsty_crow_v2.txt', 'r').read().lower()\n",
        "sentences = re.split(r'(?<=[.!?])\\s+', data)\n",
        "sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
        "print(f\"Found {len(sentences)} sentences.\")\n",
        "print(f\"Example sentences: {sentences[:2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Vocab\n",
        "words = []\n",
        "for sent in sentences:\n",
        "    word = re.findall(r\"\\w+|[.,!?'\\\";:]\", sent)\n",
        "    words.extend(word)\n",
        "\n",
        "SOS_TOKEN = '<SOS>'  # Start of Sequence\n",
        "EOS_TOKEN = '<EOS>'  # End of Sequence\n",
        "UNK_TOKEN = '<UNK>'  # Unknown word\n",
        "\n",
        "vocab = [SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + sorted(list(set(words)))\n",
        "vocab_size = len(vocab)\n",
        "word_to_ix = {w: i for i, w in enumerate(vocab)}\n",
        "ix_to_word = {i: w for i, w in enumerate(vocab)}\n",
        "\n",
        "print(f\"Vocab Size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH03BeIm72IZ",
        "outputId": "8dd1de29-1432-49a3-d134-098c1543ef73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Training Pairs (Encoder(Input), Decoder(Target))  with Teacher Forcing\n",
        "training_pairs = []\n",
        "\n",
        "for i in range(len(sentences) - 1):\n",
        "    src_text = sentences[i]\n",
        "    src_words = re.findall(r\"\\w+|[.,!?'\\\";:]\", src_text)\n",
        "    src_indices = [word_to_ix[w] for w in src_words]\n",
        "\n",
        "    trg_text = sentences[i+1]\n",
        "    trg_words = re.findall(r\"\\w+|[.,!?'\\\";:]\", trg_text)\n",
        "\n",
        "    dec_input = [word_to_ix[SOS_TOKEN]] + [word_to_ix[w] for w in trg_words] # Decoder Input: <SOS> + sentence\n",
        "    dec_target = [word_to_ix[w] for w in trg_words] + [word_to_ix[EOS_TOKEN]] # Decoder Target: sentence + <EOS>\n",
        "\n",
        "    training_pairs.append({\n",
        "        'src': src_indices,\n",
        "        'dec_input': dec_input,\n",
        "        'dec_target': dec_target\n",
        "    })\n",
        "\n",
        "print(f\"\\nExample Pair 0:\")\n",
        "print(f\"Encoder Input (Indices): {training_pairs[0]['src']}\")\n",
        "print(f\"Decoder Input (Indices): {training_pairs[0]['dec_input']}\")\n",
        "print(f\"Decoder Target (Indices): {training_pairs[0]['dec_target']}\")\n",
        "print(f\"Original Source: {sentences[0]}\")\n",
        "print(f\"Original Target: {sentences[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo_joxDV8diN",
        "outputId": "9f136679-752c-4950-87c3-7c3ebe23eaca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example Pair 0:\n",
            "Encoder Input (Indices): [65, 17, 78, 69, 3]\n",
            "Decoder Input (Indices): [0, 4, 10, 78, 77, 22, 3]\n",
            "Decoder Target (Indices): [4, 10, 78, 77, 22, 3, 1]\n",
            "Original Source: the crow was thirsty .\n",
            "Original Target: a bird was very dry .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __HYPER-PARAMETERS__"
      ],
      "metadata": {
        "id": "JhOzRBXz414W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3            # Learning rate\n",
        "hidden_size = 100    # Size of hidden state (h)\n",
        "embed_size = 100      # Size of embedding vector (e)\n",
        "MAX_LEN = 25         # Max length for generation\n",
        "clip_value = 5.0     # Gradient clipping threshold"
      ],
      "metadata": {
        "id": "InWw7ZqC3xVO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __MODEL PARAMETER INITIALIZATION__\n",
        "\n",
        "New set of weights for the Attention Mechanism and resize the Decoder to accept the context vector.\n",
        "\n",
        "**1. Shared Embeddings:**\n",
        "- $\\mathbf{W}_{emb} \\in \\mathbb{R}^{V \\times E}$: Shared lookup table.\n",
        "\n",
        "**2. Encoder Parameters:**\n",
        "- $\\mathbf{W}^{enc}_u, \\mathbf{W}^{enc}_r, \\mathbf{W}^{enc}_h \\in \\mathbb{R}^{H \\times H+E}$: Weights for Update, Reset, and Candidate gates.\n",
        "- $\\mathbf{b}^{enc}_u, \\mathbf{b}^{enc}_r, \\mathbf{b}^{enc}_h \\in \\mathbb{R}^{H \\times 1}$: Biases for the Encoder.\n",
        "\n",
        "**3. Attention Parameters:**\n",
        "This small network calculates the alignment score (energy) $e_{tj}$ between Decoder state $s_{t-1}$ and Encoder state $h_j$.\n",
        "- $\\mathbf{W}_a \\in \\mathbb{R}^{H \\times H}$: Projects the Decoder state.\n",
        "- $\\mathbf{U}_a \\in \\mathbb{R}^{H \\times H}$: Projects the Encoder state.\n",
        "- $\\mathbf{v}_a \\in \\mathbb{R}^{H \\times 1}$: Projects the activation to a scalar score.\n",
        "\n",
        "**4. The Bridge:**\n",
        "- $\\mathbf{W}_{bridge} \\in \\mathbb{R}^{H \\times H}$: Learns how to translate the Encoder's final thought into the Decoder's starting thought.\n",
        "- $\\mathbf{b}_{bridge} \\in \\mathbb{R}^{H \\times 1}$: Bias for the bridge.\n",
        "\n",
        "**5. Decoder Parameters:**\n",
        "The Decoder input is now the concatenation of the embedding ($E$) and the context vector ($H$)\n",
        "\n",
        "- $\\mathbf{W}^{dec}_u, \\mathbf{W}^{dec}_r, \\mathbf{W}^{dec}_h \\in \\mathbb{R}^{H \\times (2H+E)}$: Weights for the Decoder GRU.\n",
        "- $\\mathbf{b}^{dec}_u, \\mathbf{b}^{dec}_r, \\mathbf{b}^{dec}_h \\in \\mathbb{R}^{H \\times 1}$: Biases for the Decoder.\n",
        "- $\\mathbf{W}_y\\in \\mathbb{R}^{V \\times H}$: Hidden-to-Output weight matrix (Vocabulary projection).\n",
        "- $\\mathbf{b}_y\\in \\mathbb{R}^{V \\times 1}$: Output bias.\n",
        "\n",
        "**Where:**  \n",
        "- $V$ = vocabulary size  \n",
        "- $E$ = embedding dimension (100)  \n",
        "- $H$ = hidden size (100)"
      ],
      "metadata": {
        "id": "Rb4v9mdeqEkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Shared Embeddings\n",
        "Wemb = np.random.randn(vocab_size, embed_size) * 0.01 # Word Embeddings (V,E)\n",
        "# 2. Encoder Parameters\n",
        "Wu_enc = np.random.randn(hidden_size, hidden_size + embed_size) * 0.01 # Update Gate weights (H, H+E)\n",
        "Wr_enc = np.random.randn(hidden_size, hidden_size + embed_size) * 0.01 # Reset Gate weights (H, H+E)\n",
        "Wh_enc = np.random.randn(hidden_size, hidden_size + embed_size) * 0.01 # Candidate Hidden weights (H, H+E)\n",
        "\n",
        "bu_enc = np.zeros((hidden_size, 1)) # Update Gate bias (H, 1)\n",
        "br_enc = np.zeros((hidden_size, 1)) # Reset Gate bias (H, 1)\n",
        "bh_enc = np.zeros((hidden_size, 1)) # Candidate Hidden bias (H, 1)\n",
        "\n",
        "# 3. Attention Parameters\n",
        "Wa = np.random.randn(hidden_size, hidden_size) * 0.01 # Projects decoder hidden state (H,H)\n",
        "Ua = np.random.randn(hidden_size, hidden_size) * 0.01 # Projects encoder hidden state (H,H)\n",
        "va = np.random.randn(hidden_size, 1) * 0.01 # Projects tanh output to scalar score (H,1)\n",
        "\n",
        "# 3. Bridge Paramters\n",
        "W_bridge = np.random.randn(hidden_size, hidden_size) * 0.01 # Bridge Weights (H,H)\n",
        "b_bridge = np.zeros((hidden_size, 1)) # Bridge bias (H,1)\n",
        "\n",
        "# 4. Decoder Parameters\n",
        "Wu_dec = np.random.randn(hidden_size, 2*hidden_size + embed_size) * 0.01 # (H, 2H + E)\n",
        "Wr_dec = np.random.randn(hidden_size, 2*hidden_size + embed_size) * 0.01 # (H, 2H + E)\n",
        "Wh_dec = np.random.randn(hidden_size, 2*hidden_size + embed_size) * 0.01 # (H, 2H + E)\n",
        "\n",
        "bu_dec = np.zeros((hidden_size, 1)) # Update Gate bias (H, 1)\n",
        "br_dec = np.zeros((hidden_size, 1)) # Reset Gate bias (H, 1)\n",
        "bh_dec = np.zeros((hidden_size, 1)) # Candidate Hidden bias (H, 1)\n",
        "\n",
        "# 5. Output Layer (Only the Decoder makes predictions)\n",
        "Wy = np.random.randn(vocab_size, hidden_size) * 0.01\n",
        "by = np.zeros((vocab_size, 1))"
      ],
      "metadata": {
        "id": "e4aMeebN_1zJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "Wemb: Word Embeddings        : {Wemb.shape}\n",
        "=========================================\n",
        "         ENCODER PARAMS\n",
        "=========================================\n",
        "Wu_enc: Update Gate Weights  : {Wu_enc.shape}\n",
        "Wr_enc: Reset Gate Weights   : {Wr_enc.shape}\n",
        "Wh_enc: CHS Weights          : {Wh_enc.shape}\n",
        "bu_enc: Update Gate bias     : {bu_enc.shape}\n",
        "br_enc: Reset Gate bias      : {br_enc.shape}\n",
        "bh_enc: CHS bias             : {bh_enc.shape}\n",
        "=========================================\n",
        "         ATTENTION PARAMS\n",
        "=========================================\n",
        "Wa: Decoder State Weights    : {Wa.shape}\n",
        "Ua: Encoder State Weights    : {Ua.shape}\n",
        "va: Energy Score Weights     : {va.shape}\n",
        "=========================================\n",
        "         BRIDGE PARAMS\n",
        "=========================================\n",
        "W_bridge: Bridge Weights     : {W_bridge.shape}\n",
        "b_bridge: Bridge bias        : {b_bridge.shape}\n",
        "=========================================\n",
        "         DECODER PARAMS (Resized)\n",
        "=========================================\n",
        "Wu_dec: Update Gate Weights  : {Wu_dec.shape}\n",
        "Wr_dec: Reset Gate Weights   : {Wr_dec.shape}\n",
        "Wh_dec: CHS Weights          : {Wh_dec.shape}\n",
        "bu_dec: Update Gate bias     : {bu_dec.shape}\n",
        "br_dec: Reset Gate bias      : {br_dec.shape}\n",
        "bh_dec: CHS bias             : {bh_dec.shape}\n",
        "=========================================\n",
        "Wy: Prediction Weights       : {Wy.shape}\n",
        "by: Prediction bias          : {by.shape}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HGbspWj7RRE",
        "outputId": "b1ff3764-0dbe-494d-d340-b32c3b4d0eb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wemb: Word Embeddings        : (82, 100)\n",
            "=========================================\n",
            "         ENCODER PARAMS\n",
            "=========================================\n",
            "Wu_enc: Update Gate Weights  : (100, 200)\n",
            "Wr_enc: Reset Gate Weights   : (100, 200)\n",
            "Wh_enc: CHS Weights          : (100, 200)\n",
            "bu_enc: Update Gate bias     : (100, 1)\n",
            "br_enc: Reset Gate bias      : (100, 1)\n",
            "bh_enc: CHS bias             : (100, 1)\n",
            "=========================================\n",
            "         ATTENTION PARAMS \n",
            "=========================================\n",
            "Wa: Decoder State Weights    : (100, 100)\n",
            "Ua: Encoder State Weights    : (100, 100)\n",
            "va: Energy Score Weights     : (100, 1)\n",
            "=========================================\n",
            "         BRIDGE PARAMS\n",
            "=========================================\n",
            "W_bridge: Bridge Weights     : (100, 100)\n",
            "b_bridge: Bridge bias        : (100, 1)\n",
            "=========================================\n",
            "         DECODER PARAMS (Resized)\n",
            "=========================================\n",
            "Wu_dec: Update Gate Weights  : (100, 300)\n",
            "Wr_dec: Reset Gate Weights   : (100, 300)\n",
            "Wh_dec: CHS Weights          : (100, 300)\n",
            "bu_dec: Update Gate bias     : (100, 1)\n",
            "br_dec: Reset Gate bias      : (100, 1)\n",
            "bh_dec: CHS bias             : (100, 1)\n",
            "=========================================\n",
            "Wy: Prediction Weights       : (82, 100)\n",
            "by: Prediction bias          : (82, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __ADAM OPTIMIZER INITIALIZATION__"
      ],
      "metadata": {
        "id": "xvWhMsGbeRjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam hyperparameters\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsilon = 1e-8\n",
        "\n",
        "# 1. Embeddings\n",
        "mWemb = np.zeros_like(Wemb); vWemb = np.zeros_like(Wemb)\n",
        "\n",
        "# 2. Encoder\n",
        "mWu_enc = np.zeros_like(Wu_enc); vWu_enc = np.zeros_like(Wu_enc)\n",
        "mWr_enc = np.zeros_like(Wr_enc); vWr_enc = np.zeros_like(Wr_enc)\n",
        "mWh_enc = np.zeros_like(Wh_enc); vWh_enc = np.zeros_like(Wh_enc)\n",
        "mbu_enc = np.zeros_like(bu_enc); vbu_enc = np.zeros_like(bu_enc)\n",
        "mbr_enc = np.zeros_like(br_enc); vbr_enc = np.zeros_like(br_enc)\n",
        "mbh_enc = np.zeros_like(bh_enc); vbh_enc = np.zeros_like(bh_enc)\n",
        "\n",
        "# 3. Attention\n",
        "mWa = np.zeros_like(Wa); vWa = np.zeros_like(Wa)\n",
        "mUa = np.zeros_like(Ua); vUa = np.zeros_like(Ua)\n",
        "mva = np.zeros_like(va); vva = np.zeros_like(va)\n",
        "\n",
        "# 4. Bridge\n",
        "mW_bridge = np.zeros_like(W_bridge); vW_bridge = np.zeros_like(W_bridge)\n",
        "mb_bridge = np.zeros_like(b_bridge); vb_bridge = np.zeros_like(b_bridge)\n",
        "\n",
        "# 5. Decoder\n",
        "mWu_dec = np.zeros_like(Wu_dec); vWu_dec = np.zeros_like(Wu_dec)\n",
        "mWr_dec = np.zeros_like(Wr_dec); vWr_dec = np.zeros_like(Wr_dec)\n",
        "mWh_dec = np.zeros_like(Wh_dec); vWh_dec = np.zeros_like(Wh_dec)\n",
        "mbu_dec = np.zeros_like(bu_dec); vbu_dec = np.zeros_like(bu_dec)\n",
        "mbr_dec = np.zeros_like(br_dec); vbr_dec = np.zeros_like(br_dec)\n",
        "mbh_dec = np.zeros_like(bh_dec); vbh_dec = np.zeros_like(bh_dec)\n",
        "\n",
        "# 6. Output Layer\n",
        "mWy = np.zeros_like(Wy); vWy = np.zeros_like(Wy)\n",
        "mby = np.zeros_like(by); vby = np.zeros_like(by)\n",
        "\n",
        "# Timestep counter\n",
        "t_adam = 0"
      ],
      "metadata": {
        "id": "kkRRAXAOCEH9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z))\n",
        "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "ehegFzIZmOCo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __ATTENTION & GRU LOGIC__\n",
        "\n",
        "#### **A. The Attention Mechanism (Additive)**\n",
        "At decoding step $t$, we calculate how much focus to put on each encoder state $h_j$ based on the previous decoder state $S_{t-1}$.\n",
        "\n",
        "**1. Energy Scores ($e_{tj}$):**\n",
        "$$e_{tj} = \\mathbf{v}_a^T \\tanh(\\mathbf{W}_a s_{t-1} + \\mathbf{U}_a h_j)$$\n",
        "*Note: This uses broadcasting to add the projected decoder vector to every projected encoder column.*\n",
        "\n",
        "**2. Attention Weights ($\\alpha_{tj}$):**\n",
        "We apply Softmax over the time dimension ($j=1 \\dots T_{enc}$) to get probabilities.\n",
        "$$\\alpha_{tj} = \\frac{\\exp(e_{tj})}{\\sum_{k=1}^{T} \\exp(e_{tk})}$$\n",
        "\n",
        "**3. Context Vector ($c_t$):**\n",
        "The weighted sum of encoder states.\n",
        "$$c_t = \\sum_{j=1}^{T} \\alpha_{tj} h_j$$\n",
        "\n",
        "\n",
        "#### **B. Decoder GRU Step**\n",
        "The Decoder takes the context vector $c_t$ alongside the word embedding $y_{t-1}$.\n",
        "\n",
        "**Input:** $\\mathbf{x}^{dec}_t = [y_{t-1}; c_t]$ (Concatenation)\n",
        "\n",
        "**Update Gate:**\n",
        "$$\\mathbf{z}_u = \\mathbf{W}^{dec}_u [s_{t-1}; \\mathbf{x}^{dec}_t] + \\mathbf{b}^{dec}_u$$\n",
        "\n",
        "*(Other gates follow the standard GRU pattern using this concatenated input)*"
      ],
      "metadata": {
        "id": "MBIC1YOBrEPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODER\n",
        "def encoder_step(h_prev, word_idx):\n",
        "    \"\"\"\n",
        "    Single GRU step for the Encoder. Uses _enc weights and DOES NOT compute output yt.\n",
        "    \"\"\"\n",
        "    et = Wemb[word_idx].reshape(-1, 1)  # (E, 1)\n",
        "    zt = np.concatenate((h_prev, et), axis=0) # (H+E, 1)\n",
        "    zu = np.dot(Wu_enc, zt) + bu_enc #(H,H+E)@(H+E,1)->(H,1)+(H,1)=(H,1)\n",
        "    ut = sigmoid(zu) # (H,1)\n",
        "    zr = np.dot(Wr_enc, zt) + br_enc ##(H,H+E)@(H+E,1)->(H,1)+(H,1)=(H,1)\n",
        "    rt = sigmoid(zr) # (H,1)\n",
        "    Wh_h = Wh_enc[:, :hidden_size] # (H,H)\n",
        "    Wh_x = Wh_enc[:, hidden_size:] # (H,E)\n",
        "    zcht = np.dot(Wh_x, et) + rt * np.dot(Wh_h, h_prev) + bh_enc #(H,1)\n",
        "    cht = np.tanh(zcht) # (H,1)\n",
        "    ht = (1 - ut) * cht + ut * h_prev # (H,1)*(H,1) + (H,1)*(H,1)=(H,1)\n",
        "    return et, ut, rt, cht, ht\n",
        "\n",
        "# ATTENTION MECHANISM\n",
        "def calculate_attention(s_prev, enc_matrix):\n",
        "    \"\"\"\n",
        "    Bahdanau Attention (Additive).\n",
        "\n",
        "    Inputs:\n",
        "        - s_prev: Decoder's previous hidden state (H, 1)\n",
        "        - enc_matrix: All Encoder hidden states stacked (H, Seq_Len(T))\n",
        "\n",
        "    Returns:\n",
        "        - context_vector: Weighted sum of encoder states (H, 1)\n",
        "        - alphas: Attention weights (1, Seq_Len) - for visualization\n",
        "        - energy: Raw scores (needed for backprop)\n",
        "    \"\"\"\n",
        "    # 1. Calculate Energy Scores\n",
        "    decoder_proj = np.dot(Wa, s_prev) #(H,H)@(H,1)=(H,1)\n",
        "    encoder_proj = np.dot(Ua, enc_matrix) #(H,H)@(H,seq_len)=(H,seq_len(T))\n",
        "    activation = np.tanh(decoder_proj + encoder_proj) #(H,1)+(H,seq_len)=(H,seq_len) -Broadcasting\n",
        "    energy = np.dot(va.T, activation) # (1,H)@(H,seq_len)=(1,seq_len)\n",
        "\n",
        "    # 2. Calculate Attention Weights (Softmax)\n",
        "    exp_energy = np.exp(energy - np.max(energy))\n",
        "    alphas = exp_energy / np.sum(exp_energy, axis=1, keepdims=True) # (1, seq_Len)\n",
        "\n",
        "    # 3. Calculate Context Vector\n",
        "    context_vector = np.dot(enc_matrix, alphas.T) # (H,seq_len)@(seq_len,1)=(H,1)\n",
        "    return context_vector, alphas, energy\n",
        "\n",
        "\n",
        "# DECODER\n",
        "def decoder_step(h_prev, word_idx, context_vector):\n",
        "    \"\"\"\n",
        "    Single GRU step for the Decoder with Attention.\n",
        "\n",
        "    Changes:\n",
        "    - Input is now [Embedding; Context Vector] instead of just Embedding.\n",
        "    \"\"\"\n",
        "    et = Wemb[word_idx].reshape(-1, 1) # (E, 1)\n",
        "    gru_input = np.concatenate((et, context_vector), axis=0) #(E,1)+(H,1)=(E+H,1)\n",
        "    zt = np.concatenate((h_prev, gru_input), axis=0) #(H,1)+(E+H,1)=(2H+E,1)\n",
        "\n",
        "    # GRU Logic\n",
        "    zu = np.dot(Wu_dec, zt) + bu_dec # (H,2H+E)@(2H+E,1)=(H,1)+(H,1)=(H,1)\n",
        "    ut = sigmoid(zu) #(H,1)\n",
        "\n",
        "    zr = np.dot(Wr_dec, zt) + br_dec # (H,2H+E)@(2H+E,1)=(H,1)+(H,1)=(H,1)\n",
        "    rt = sigmoid(zr) #(H,1)\n",
        "\n",
        "    # Split Wh for candidate calculation\n",
        "    Wh_h = Wh_dec[:, :hidden_size]      # (H, H)\n",
        "    Wh_x = Wh_dec[:, hidden_size:]      # (H, E+H)\n",
        "    zcht = np.dot(Wh_x, gru_input) + rt * np.dot(Wh_h, h_prev) + bh_dec\n",
        "    # (H,E+H)@(E+H,1)=(H,1)+(H,1)*(H,H)@(H,1):(H,1)=(H,1)\n",
        "    cht = np.tanh(zcht) #(H,1)\n",
        "\n",
        "    ht = (1 - ut) * cht + ut * h_prev #(H,1)\n",
        "    yt = np.dot(Wy, ht) + by #(V,1)\n",
        "    return et, ut, rt, cht, ht, yt"
      ],
      "metadata": {
        "id": "FDO_yCnzC5Tt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __UNDERSTANDING THE GRU CELLS WITH ATTENTION__\n",
        "\n",
        "The attention mechanism changes how the Decoder processes information compared to the standard Encoder-Decoder.\n",
        "\n",
        "**1. Encoder GRU (The Reader)**\n",
        "- **Inputs:** Current word embedding $\\mathbf{e}_t$ and Previous hidden state $\\mathbf{h}_{t-1}$.\n",
        "- **Action:** Processes the source sentence and produces a sequence of hidden states $\\{h_1, h_2, \\dots, h_T\\}$.\n",
        "- **Outputs:**\n",
        "  1. Hidden state at each timestep $\\mathbf{h}_t$ (all states are kept, not just the final one).\n",
        "  2. Cache values $(\\mathbf{e}_t, \\mathbf{u}_t, \\mathbf{r}_t, \\tilde{\\mathbf{h}}_t)$ for backprop.\n",
        "- **Note:** Does **not** produce output logits ($\\mathbf{y}_t$).\n",
        "\n",
        "**2. Attention Mechanism (The Focus)**\n",
        "- **Purpose:** At each decoder step, dynamically compute which encoder states are most relevant.\n",
        "- **Process:**\n",
        "  1. Compare decoder state $s_{t-1}$ with all encoder states\n",
        "  2. Compute attention weights $\\alpha_{tj}$ (how much to focus on each encoder position)\n",
        "  3. Create context vector $c_t$ as weighted sum of encoder states\n",
        "- **Key Benefit:** No fixed bottleneck—decoder can \"look back\" at the entire source sentence.\n",
        "\n",
        "**3. Decoder GRU (The Writer with Context Awareness)**\n",
        "- **Inputs:**\n",
        "  1. Current word embedding $\\mathbf{e}_t$ (from Teacher Forcing or previous prediction)\n",
        "  2. **Context vector $\\mathbf{c}_t$** from attention mechanism\n",
        "  3. Previous decoder state $s_{t-1}$\n",
        "- **Key Change:** The GRU input is now $[\\mathbf{e}_t; \\mathbf{c}_t]$ instead of just $\\mathbf{e}_t$\n",
        "- **Action:** Updates memory using context-aware information and predicts next word.\n",
        "- **Outputs:**\n",
        "  1. New hidden state $s_t$.\n",
        "  2. **Logits $\\mathbf{y}_t$** (Projected to vocabulary size).\n",
        "  3. Cache values $(\\mathbf{e}_t, \\mathbf{u}_t, \\mathbf{r}_t, \\tilde{\\mathbf{h}}_t)$.\n",
        "\n",
        "**Flow Summary:**\n",
        "```\n",
        "Source → Encoder → [h₁, h₂, ..., hₜ] → Attention → Context → Decoder → Prediction\n",
        "                          ↑_______________|\n",
        "```\n",
        "The decoder's attention weights at each step determine which parts of the source sentence are most important for generating the current target word."
      ],
      "metadata": {
        "id": "4f5wu1Tj9rbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __FORWARD PASS__\n"
      ],
      "metadata": {
        "id": "JSiqg1u1Fcuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(src_inputs, dec_inputs, dec_targets):\n",
        "    \"\"\"\n",
        "    Forward pass with Bahdanau Attention.\n",
        "\n",
        "    Returns:\n",
        "        - loss: Scalar loss\n",
        "        - caches: grouping of all intermediate values for backprop\n",
        "    \"\"\"\n",
        "    # ENCODER PHASE\n",
        "    enc_et, enc_ut, enc_rt, enc_cht, enc_ht = {}, {}, {}, {}, {}\n",
        "    h_enc_init = np.zeros((hidden_size, 1))\n",
        "    enc_ht[-1] = h_enc_init\n",
        "    for t in range(len(src_inputs)):\n",
        "        word_idx = src_inputs[t]\n",
        "        enc_et[t], enc_ut[t], enc_rt[t], enc_cht[t], enc_ht[t] = encoder_step(enc_ht[t-1], word_idx)\n",
        "\n",
        "    # Stack all hidden states columns side-by-side for matrix multiplication\n",
        "    # enc_ht[t] is (H, 1), so concatenating on axis 1 gives (H, seq_len(T))\n",
        "    enc_list = [enc_ht[t] for t in range(len(src_inputs))]\n",
        "    enc_matrix = np.concatenate(enc_list, axis=1)\n",
        "\n",
        "    # BRIDGE\n",
        "    h_enc_final = enc_ht[len(src_inputs) - 1] # (H,1)\n",
        "    bridge_z = np.dot(W_bridge, h_enc_final) + b_bridge # (H,1)\n",
        "    h_dec_init = np.tanh(bridge_z) # (H,1)\n",
        "    bridge_cache = (h_enc_final, bridge_z, h_dec_init) # (H,1)\n",
        "\n",
        "    # DECODER PHASE\n",
        "    dec_et, dec_ut, dec_rt, dec_cht, dec_ht, dec_yt = {}, {}, {}, {}, {}, {}\n",
        "    dec_probt = {}\n",
        "    # ATTENTION CACHES\n",
        "    attn_contexts = {}  # Store c_t\n",
        "    attn_alphas = {}    # Store alpha_t (for visualization)\n",
        "    attn_energies = {}  # Store e_t\n",
        "\n",
        "    dec_ht[-1] = np.copy(h_dec_init)\n",
        "    loss = 0\n",
        "\n",
        "    for t in range(len(dec_inputs)):\n",
        "        word_idx = dec_inputs[t]\n",
        "        target_idx = dec_targets[t]\n",
        "        context, alpha, energy = calculate_attention(dec_ht[t-1], enc_matrix)\n",
        "        attn_contexts[t] = context\n",
        "        attn_alphas[t] = alpha\n",
        "        attn_energies[t] = energy\n",
        "        # Decoder Step\n",
        "        dec_et[t], dec_ut[t], dec_rt[t], dec_cht[t], dec_ht[t], dec_yt[t] = decoder_step(dec_ht[t-1], word_idx, context)\n",
        "        dec_probt[t] = softmax(dec_yt[t])\n",
        "        loss += -np.log(dec_probt[t][target_idx, 0] + epsilon)\n",
        "\n",
        "    enc_cache = (enc_et, enc_ut, enc_rt, enc_cht, enc_ht, enc_matrix)\n",
        "    dec_cache = (dec_et, dec_ut, dec_rt, dec_cht, dec_ht, dec_yt, dec_probt)\n",
        "    attn_cache = (attn_contexts, attn_alphas, attn_energies)\n",
        "\n",
        "    return loss, enc_cache, bridge_cache, dec_cache, attn_cache"
      ],
      "metadata": {
        "id": "zLGSwkThGX1R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __BACKWARD PASS (BPTT) WITH ATTENTION__\n",
        "\n",
        "**Backpropagation Through Time for Encoder-Decoder with Bahdanau Attention**\n",
        "\n",
        "### **DECODER BACKWARD PASS**\n",
        "\n",
        "#### **Step 1: Output Layer Gradient (Softmax + Cross-Entropy)**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} = \\mathbf{p}_t - \\mathbf{1}_{y^*_t}$$\n",
        "\n",
        "**Output layer weight gradients:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_y} = \\sum_{t=0}^{T_{dec}-1} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} (\\mathbf{s}_t)^T$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_y} = \\sum_{t=0}^{T_{dec}-1} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t}$$\n",
        "\n",
        "#### **Step 2: Decoder Hidden State Gradient**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_t} = \\mathbf{W}_y^T \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_{t+1}}$$\n",
        "\n",
        "The gradient flows from:\n",
        "- Current timestep's output loss (first term)\n",
        "- Future timestep's hidden state (second term)\n",
        "- **Attention mechanism** (additional gradient path)\n",
        "\n",
        "### **ATTENTION MECHANISM BACKWARD PASS**\n",
        "\n",
        "#### **Step 3: Gradient w.r.t. Context Vector**\n",
        "\n",
        "From the decoder GRU, we receive $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t}$ (gradient w.r.t. context).\n",
        "\n",
        "**Context Calculation (Forward):**\n",
        "$$\\mathbf{c}_t = \\sum_{j=1}^{T_{enc}} \\alpha_{tj} \\mathbf{h}_j = \\mathbf{H} \\boldsymbol{\\alpha}_t^T$$\n",
        "\n",
        "Where $\\mathbf{H} = [\\mathbf{h}_1, \\mathbf{h}_2, \\dots, \\mathbf{h}_{T_{enc}}] \\in \\mathbb{R}^{H \\times T_{enc}}$\n",
        "\n",
        "**Gradients:**\n",
        "\n",
        "1. **Gradient w.r.t. Attention Weights:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\alpha}_t} = \\mathbf{H}^T \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t}$$\n",
        "Shape: $(T_{enc}, H) \\times (H, 1) = (T_{enc}, 1) \\rightarrow$ transpose to $(1, T_{enc})$\n",
        "\n",
        "2. **Gradient w.r.t. Encoder States (from context):**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{H}} += \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t} \\boldsymbol{\\alpha}_t$$\n",
        "Shape: $(H, 1) \\times (1, T_{enc}) = (H, T_{enc})$\n",
        "\n",
        "#### **Step 4: Softmax Gradient**\n",
        "\n",
        "**Forward:** $\\boldsymbol{\\alpha}_t = \\text{softmax}(\\mathbf{e}_t)$\n",
        "\n",
        "**Backward (Softmax Jacobian):**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{e}_t} = \\boldsymbol{\\alpha}_t \\odot \\left(\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\alpha}_t} - \\sum_k \\alpha_{tk} \\frac{\\partial \\mathcal{L}}{\\partial \\alpha_{tk}}\\right)$$\n",
        "\n",
        "Shape: $(1, T_{enc})$\n",
        "\n",
        "#### **Step 5: Energy Score Gradients**\n",
        "\n",
        "**Forward:**\n",
        "$$e_{tj} = \\mathbf{v}_a^T \\tanh(\\mathbf{W}_a \\mathbf{s}_{t-1} + \\mathbf{U}_a \\mathbf{h}_j)$$\n",
        "\n",
        "**Backward:**\n",
        "\n",
        "1. **Gradient w.r.t. Activation:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}_t} = \\mathbf{v}_a \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{e}_t}$$\n",
        "Where $\\mathbf{A}_t = \\tanh(\\mathbf{W}_a \\mathbf{s}_{t-1} + \\mathbf{U}_a \\mathbf{H})$ of shape $(H, T_{enc})$\n",
        "\n",
        "2. **Gradient through Tanh:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{A}_t} \\odot (1 - \\mathbf{A}_t^2)$$\n",
        "\n",
        "3. **Attention Parameter Gradients:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{v}_a} = \\mathbf{A}_t \\left(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{e}_t}\\right)^T$$\n",
        "Shape: $(H, T_{enc}) \\times (T_{enc}, 1) = (H, 1)$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_a} = \\left(\\sum_{j=1}^{T_{enc}} \\frac{\\partial \\mathcal{L}}{\\partial z_{tj}}\\right) \\mathbf{s}_{t-1}^T$$\n",
        "Shape: $(H, 1) \\times (1, H) = (H, H)$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{U}_a} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_t} \\mathbf{H}^T$$\n",
        "Shape: $(H, T_{enc}) \\times (T_{enc}, H) = (H, H)$\n",
        "\n",
        "4. **Gradients to Previous States:**\n",
        "\n",
        "   - **To Decoder State $\\mathbf{s}_{t-1}$:**\n",
        "   $$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_{t-1}} += \\mathbf{W}_a^T \\left(\\sum_{j=1}^{T_{enc}} \\frac{\\partial \\mathcal{L}}{\\partial z_{tj}}\\right)$$\n",
        "   \n",
        "   - **To Encoder States $\\mathbf{H}$:**\n",
        "   $$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{H}} += \\mathbf{U}_a^T \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_t}$$\n",
        "\n",
        "### **GRU GATE GRADIENTS (Encoder & Decoder)**\n",
        "\n",
        "The GRU backward pass follows the standard formulas, with one key difference for the decoder:\n",
        "\n",
        "**Decoder Input:** $[\\mathbf{s}_{t-1}; \\mathbf{e}_t; \\mathbf{c}_t] \\in \\mathbb{R}^{(2H+E) \\times 1}$\n",
        "\n",
        "This affects the weight matrix dimensions and gradient splitting.\n",
        "\n",
        "#### **Step 6: Update Gate Gradients**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{u}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_t} \\odot (\\mathbf{s}_{t-1} - \\tilde{\\mathbf{s}}_t)$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_u} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{u}_t} \\odot \\mathbf{u}_t \\odot (1 - \\mathbf{u}_t)$$\n",
        "\n",
        "#### **Step 7: Candidate Hidden State Gradients**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\tilde{\\mathbf{s}}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_t} \\odot (1 - \\mathbf{u}_t)$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} = \\frac{\\partial \\mathcal{L}}{\\partial \\tilde{\\mathbf{s}}_t} \\odot (1 - \\tilde{\\mathbf{s}}_t^2)$$\n",
        "\n",
        "#### **Step 8: Reset Gate Gradients**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{r}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} \\odot (\\mathbf{W}_{h,h} \\mathbf{s}_{t-1})$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_r} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{r}_t} \\odot \\mathbf{r}_t \\odot (1 - \\mathbf{r}_t)$$\n",
        "\n",
        "#### **Step 9: Weight Matrix Gradients**\n",
        "\n",
        "**Decoder GRU** (with concatenated input $[\\mathbf{s}_{t-1}; \\mathbf{e}_t; \\mathbf{c}_t]$):\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_u^{dec}} = \\sum_{t=0}^{T_{dec}-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_u} [\\mathbf{s}_{t-1}; \\mathbf{e}_t; \\mathbf{c}_t]^T$$\n",
        "\n",
        "Similar for $\\mathbf{W}_r^{dec}$, with special handling for $\\mathbf{W}_h^{dec}$:\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{h,h}^{dec}} = \\sum_{t=0}^{T_{dec}-1} (\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} \\odot \\mathbf{r}_t) \\mathbf{s}_{t-1}^T$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{h,x}^{dec}} = \\sum_{t=0}^{T_{dec}-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} [\\mathbf{e}_t; \\mathbf{c}_t]^T$$\n",
        "\n",
        "**Encoder GRU** uses standard formulas with input $[\\mathbf{h}_{t-1}; \\mathbf{e}_t]$.\n",
        "\n",
        "#### **Step 10: Gradient to Previous Hidden State**\n",
        "\n",
        "**Decoder:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_{t-1}} = \\text{(GRU gradients)} + \\text{(Attention gradients)}$$\n",
        "\n",
        "The decoder state receives gradients from:\n",
        "1. GRU gates (4 paths as in standard GRU)\n",
        "2. Attention mechanism (via $\\mathbf{W}_a$)\n",
        "\n",
        "**Encoder:**\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_j} = \\text{(GRU gradients)} + \\text{(Attention gradients from all decoder steps)}$$\n",
        "\n",
        "Each encoder state receives gradients from:\n",
        "1. Next encoder timestep (standard BPTT)\n",
        "2. **All decoder attention computations** where it was attended to\n",
        "3. Bridge (for final state only)\n",
        "\n",
        "### **BRIDGE BACKWARD PASS**\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{bridge}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{s}_{-1}} \\odot (1 - (\\mathbf{s}_{-1})^2)$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{bridge}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{bridge}} (\\mathbf{h}_{final}^{enc})^T$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{final}^{enc}} = \\mathbf{W}_{bridge}^T \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{bridge}}$$\n",
        "\n",
        "### **Encoder GRU**\n",
        "uses standard formulas with input $[\\mathbf{h}_{t-1}; \\mathbf{e}_t]$:\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{h,h}^{enc}} = \\sum_{t=0}^{T_{enc}-1} (\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} \\odot \\mathbf{r}_t) \\mathbf{h}_{t-1}^T$$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{h,x}^{enc}} = \\sum_{t=0}^{T_{enc}-1} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_h} \\mathbf{e}_t^T$$\n",
        "\n",
        "**Notation:**\n",
        "- $T_{enc}$ = encoder sequence length\n",
        "- $T_{dec}$ = decoder sequence length  \n",
        "- $H$ = hidden dimension\n",
        "- $E$ = embedding dimension\n",
        "- $V$ = vocabulary size\n",
        "- $\\mathbf{s}_t$ = decoder hidden state\n",
        "- $\\mathbf{h}_j$ = encoder hidden state at position $j$\n",
        "- $\\boldsymbol{\\alpha}_t$ = attention weights at decoder step $t$"
      ],
      "metadata": {
        "id": "omDbD9a2tPsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(src_inputs, dec_inputs, dec_targets, enc_cache, bridge_cache, dec_cache, attn_cache):\n",
        "    \"\"\"\n",
        "    BPTT for Encoder-Decoder with Bahdanau Attention.\n",
        "    \"\"\"\n",
        "    enc_et, enc_ut, enc_rt, enc_cht, enc_ht, enc_matrix = enc_cache\n",
        "    h_enc_final, bridge_z, h_dec_init = bridge_cache\n",
        "    dec_et, dec_ut, dec_rt, dec_cht, dec_ht, dec_yt, dec_probt = dec_cache\n",
        "    attn_contexts, attn_alphas, attn_energies = attn_cache\n",
        "\n",
        "    # INITIALIZE GRADIENTS\n",
        "    dWemb = np.zeros_like(Wemb)\n",
        "    # Encoder Gradients\n",
        "    dWu_enc = np.zeros_like(Wu_enc); dWr_enc = np.zeros_like(Wr_enc); dWh_enc = np.zeros_like(Wh_enc)\n",
        "    dbu_enc = np.zeros_like(bu_enc); dbr_enc = np.zeros_like(br_enc); dbh_enc = np.zeros_like(bh_enc)\n",
        "    # Attention Gradients\n",
        "    dWa = np.zeros_like(Wa); dUa = np.zeros_like(Ua); dva = np.zeros_like(va)\n",
        "    # Bridge Gradients\n",
        "    dW_bridge = np.zeros_like(W_bridge); db_bridge = np.zeros_like(b_bridge)\n",
        "    # Decoder Gradients\n",
        "    dWu_dec = np.zeros_like(Wu_dec); dWr_dec = np.zeros_like(Wr_dec); dWh_dec = np.zeros_like(Wh_dec)\n",
        "    dbu_dec = np.zeros_like(bu_dec); dbr_dec = np.zeros_like(br_dec); dbh_dec = np.zeros_like(bh_dec)\n",
        "    dWy = np.zeros_like(Wy); dby = np.zeros_like(by)\n",
        "    d_enc_matrix = np.zeros_like(enc_matrix) # This matrix will collect gradients flowing from Attention to Encoder States (H, Seq_Len)\n",
        "    dh_next = np.zeros_like(dec_ht[-1]) # (H, 1)\n",
        "\n",
        "    # DECODER BACKWARD\n",
        "    for t in reversed(range(len(dec_inputs))):\n",
        "        # A. Output Layer Gradients\n",
        "        dy = np.copy(dec_probt[t])\n",
        "        dy[dec_targets[t]] -= 1 # (V, 1)\n",
        "        dWy += np.dot(dy, dec_ht[t].T) # (V, H)\n",
        "        dby += dy # (V, 1)\n",
        "\n",
        "        # Gradient into Decoder State s_t\n",
        "        dh = np.dot(Wy.T, dy) + dh_next # (H, 1)\n",
        "\n",
        "        # B. Decoder GRU Gradients\n",
        "        s_prev = dec_ht[t-1]\n",
        "        # Input to GRU was [embedding; context]\n",
        "        gru_input = np.concatenate((dec_et[t], attn_contexts[t]), axis=0) # (E+H, 1)\n",
        "        # GRU gates\n",
        "        du = dh * (s_prev - dec_cht[t])\n",
        "        dzu = du * dec_ut[t] * (1 - dec_ut[t]) # (H,1)\n",
        "\n",
        "        dcht = dh * (1 - dec_ut[t])\n",
        "        dzh = dcht * (1 - dec_cht[t]**2) # (H,1)\n",
        "\n",
        "        Wh_h_dec = Wh_dec[:, :hidden_size] # (H,H)\n",
        "\n",
        "        # Reset Gate\n",
        "        dr = dzh * np.dot(Wh_h_dec, s_prev) # (H,1)\n",
        "        dzr = dr * dec_rt[t] * (1 - dec_rt[t]) # (H,1)\n",
        "\n",
        "        # Weight Gradients\n",
        "        zt = np.concatenate((s_prev, gru_input), axis=0) # (2H+E, 1)\n",
        "        dWu_dec += np.dot(dzu, zt.T) #(H,1)@(1,2H+E)=(H,2H+E)\n",
        "        dbu_dec += dzu #(H,1)\n",
        "        dWr_dec += np.dot(dzr, zt.T) #(H,1)@(1,2H+E)=(H,2H+E)\n",
        "        dbr_dec += dzr #(H,1)\n",
        "\n",
        "        # Candidate Weights\n",
        "        dWh_dec[:, :hidden_size] += np.dot(dzh * dec_rt[t], s_prev.T) #(H,1)@(1,H)=(H,H)\n",
        "        dWh_dec[:, hidden_size:] += np.dot(dzh, gru_input.T) #(H,1)@(1,E+H)=(H,E+H)\n",
        "        dbh_dec += dzh #(H,1)\n",
        "\n",
        "        # Split Gradients for GRU Input [Embedding; Context]\n",
        "        d_zt_input = (np.dot(Wu_dec.T, dzu) + np.dot(Wr_dec.T, dzr) + np.dot(Wh_dec.T, dzh)) # (2H+E, 1)\n",
        "        # The bottom part of zt is gru_input (size E+H)\n",
        "        d_gru_input = d_zt_input[hidden_size:, :] # (E+H, 1)\n",
        "\n",
        "        # Split into Embedding and Context\n",
        "        d_embed = d_gru_input[:embed_size, :] # (E, 1)\n",
        "        d_context = d_gru_input[embed_size:, :] # (H, 1)\n",
        "\n",
        "        # Accumulate Embedding Gradient\n",
        "        dWemb[dec_inputs[t]] += d_embed.ravel()\n",
        "\n",
        "        # ATTENTION BACKPROP (go back through calculate_attention)\n",
        "        # 1. Gradient w.r.t Alphas\n",
        "        d_alphas = np.dot(d_context.T, enc_matrix) # (1,H) @ (H,T) = (1,T)\n",
        "\n",
        "        # 2. Gradient w.r.t Energy (Backprop Softmax)\n",
        "        alphas = attn_alphas[t] # (1, T)\n",
        "        d_energy = alphas * (d_alphas - np.sum(alphas * d_alphas, axis=1, keepdims=True)) # (1, T)\n",
        "\n",
        "        # 3. Gradient w.r.t Tanh Activation (in score calculation)\n",
        "        d_activation = np.dot(va, d_energy) # (H,1) @ (1,T) = (H,T)\n",
        "\n",
        "        # 4. Backprop Tanh\n",
        "        dec_proj = np.dot(Wa, s_prev) # (H,H) @ (H,1)=(H,1)\n",
        "        enc_proj = np.dot(Ua, enc_matrix) # (H,H) @ (H,T)=(H,T)\n",
        "        activation_val = np.tanh(dec_proj + enc_proj)\n",
        "        d_raw_scores = d_activation * (1 - activation_val**2) # (H,T)\n",
        "\n",
        "        # 5. Gradients for Attention Weights (Wa, Ua, va)\n",
        "        # dva: energy = va.T @ activation -> dva = activation @ d_energy.T\n",
        "        dva += np.dot(activation_val, d_energy.T) # (H, T) @ (T, 1) = (H, 1)\n",
        "\n",
        "        d_dec_proj = np.sum(d_raw_scores, axis=1, keepdims=True) # (H,1)\n",
        "        dWa += np.dot(d_dec_proj, s_prev.T) # (H,1) @ (1,H) = (H,H)\n",
        "        dUa += np.dot(d_raw_scores, enc_matrix.T) # (H,T) @ (T,H) = (H,H)\n",
        "\n",
        "        # 6. Gradients Flowing Backwards To Decoder Previous State (s_prev)\n",
        "        # Flows from GRU (dh_next_gru) AND Attention (d_dec_proj)\n",
        "        # From GRU gates\n",
        "        dh_from_zu = np.dot(Wu_dec.T, dzu)[:hidden_size, :]\n",
        "        dh_from_zr = np.dot(Wr_dec.T, dzr)[:hidden_size, :]\n",
        "        dh_from_zh = np.dot(Wh_h_dec.T, dzh * dec_rt[t])\n",
        "        dh_from_direct = dh * dec_ut[t]\n",
        "        dh_prev_gru = dh_from_zu + dh_from_zr + dh_from_zh + dh_from_direct\n",
        "        dh_prev_attn = np.dot(Wa.T, d_dec_proj) # (H,H) @ (H,1) = (H,1)\n",
        "        dh_next = dh_prev_gru + dh_prev_attn\n",
        "\n",
        "        # To Encoder Matrix (H, T)\n",
        "        # Flows from Context calculation AND Attention Ua calculation\n",
        "        d_enc_matrix += np.dot(d_context, alphas) # (H,1) @ (1,T) = (H,T)\n",
        "        d_enc_matrix += np.dot(Ua.T, d_raw_scores) # (H,H) @ (H,T) = (H,T)\n",
        "\n",
        "    # BRIDGE BACKWARD\n",
        "    # Gradient from decoder init state\n",
        "    d_h_dec_init = dh_next #(H,1)\n",
        "\n",
        "    d_bridge_z = d_h_dec_init * (1 - h_dec_init**2) #(H,1)\n",
        "    dW_bridge = np.dot(d_bridge_z, h_enc_final.T)\n",
        "    db_bridge = d_bridge_z\n",
        "    d_h_enc_final = np.dot(W_bridge.T, d_bridge_z) #(H,1)\n",
        "\n",
        "    # ENCODER BACKWARD\n",
        "    # Add bridge gradient to the last timestep of accumulated matrix\n",
        "    d_enc_matrix[:, -1] += d_h_enc_final.ravel()\n",
        "\n",
        "    dh_next = np.zeros_like(h_enc_final) # Re-init for encoder loop\n",
        "\n",
        "    for t in reversed(range(len(src_inputs))):\n",
        "        dh = dh_next + d_enc_matrix[:, t].reshape(-1, 1)\n",
        "\n",
        "        du = dh * (enc_ht[t-1] - enc_cht[t])\n",
        "        dzu = du * enc_ut[t] * (1 - enc_ut[t])\n",
        "\n",
        "        dcht = dh * (1 - enc_ut[t])\n",
        "        dzh = dcht * (1 - enc_cht[t]**2)\n",
        "\n",
        "        Wh_h_enc = Wh_enc[:, :hidden_size]\n",
        "\n",
        "        dr = dzh * np.dot(Wh_h_enc, enc_ht[t-1])\n",
        "        dzr = dr * enc_rt[t] * (1 - enc_rt[t])\n",
        "\n",
        "        z_cat = np.concatenate((enc_ht[t-1], enc_et[t]), axis=0)\n",
        "        dWu_enc += np.dot(dzu, z_cat.T)\n",
        "        dbu_enc += dzu\n",
        "        dWr_enc += np.dot(dzr, z_cat.T)\n",
        "        dbr_enc += dzr\n",
        "\n",
        "        dWh_enc[:, :hidden_size] += np.dot(dzh * enc_rt[t], enc_ht[t-1].T)\n",
        "        dWh_enc[:, hidden_size:] += np.dot(dzh, enc_et[t].T)\n",
        "        dbh_enc += dzh\n",
        "\n",
        "        de = (np.dot(Wu_enc.T, dzu) + np.dot(Wr_enc.T, dzr) + np.dot(Wh_enc.T, dzh))[hidden_size:, :]\n",
        "        dWemb[src_inputs[t]] += de.ravel()\n",
        "\n",
        "        dh_from_zu = np.dot(Wu_enc.T, dzu)[:hidden_size, :]\n",
        "        dh_from_zr = np.dot(Wr_enc.T, dzr)[:hidden_size, :]\n",
        "        dh_from_zh = np.dot(Wh_h_enc.T, dzh * enc_rt[t])\n",
        "        dh_from_direct = dh * enc_ut[t]\n",
        "\n",
        "        dh_next = dh_from_zu + dh_from_zr + dh_from_zh + dh_from_direct\n",
        "\n",
        "    grads = [dWemb, dWu_enc, dWr_enc, dWh_enc,\n",
        "             dWa, dUa, dva,\n",
        "             dW_bridge,\n",
        "             dWu_dec, dWr_dec, dWh_dec, dWy,\n",
        "             dbu_enc, dbr_enc, dbh_enc,\n",
        "             db_bridge,\n",
        "             dbu_dec, dbr_dec, dbh_dec, dby]\n",
        "\n",
        "    for grad in grads:\n",
        "        np.clip(grad, -clip_value, clip_value, out=grad)\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "j7TxWOeuSGtG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __UPDATE PARAMS WITH ADAM__"
      ],
      "metadata": {
        "id": "whAHx2WTW03k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update all Encoder, Bridge, Decoder, AND Attention parameters using Adam.\n",
        "    \"\"\"\n",
        "    # 1. Declare Globals (Model Weights)\n",
        "    global Wemb\n",
        "    global Wu_enc, Wr_enc, Wh_enc, bu_enc, br_enc, bh_enc\n",
        "    global Wu_dec, Wr_dec, Wh_dec, bu_dec, br_dec, bh_dec, Wy, by\n",
        "    global W_bridge, b_bridge\n",
        "    # Attention Globals\n",
        "    global Wa, Ua, va\n",
        "\n",
        "    # 2. Declare Globals (Adam Memory)\n",
        "    global mWemb, vWemb\n",
        "    global mWu_enc, vWu_enc, mWr_enc, vWr_enc, mWh_enc, vWh_enc, mbu_enc, vbu_enc, mbr_enc, vbr_enc, mbh_enc, vbh_enc\n",
        "    global mWu_dec, vWu_dec, mWr_dec, vWr_dec, mWh_dec, vWh_dec, mbu_dec, vbu_dec, mbr_dec, vbr_dec, mbh_dec, vbh_dec, mWy, vWy, mby, vby\n",
        "    global mW_bridge, vW_bridge, mb_bridge, vb_bridge\n",
        "    # Attention Memory\n",
        "    global mWa, vWa, mUa, vUa, mva, vva\n",
        "\n",
        "    global t_adam\n",
        "    t_adam += 1\n",
        "\n",
        "    # 3. Unpack Gradients\n",
        "    (dWemb,\n",
        "     dWu_enc, dWr_enc, dWh_enc,\n",
        "     dWa, dUa, dva,\n",
        "     dW_bridge,\n",
        "     dWu_dec, dWr_dec, dWh_dec, dWy,\n",
        "     dbu_enc, dbr_enc, dbh_enc,\n",
        "     db_bridge,\n",
        "     dbu_dec, dbr_dec, dbh_dec, dby) = grads\n",
        "\n",
        "    # 4. Create Param List\n",
        "    params = [\n",
        "        (Wemb, dWemb, mWemb, vWemb),\n",
        "\n",
        "        # Encoder\n",
        "        (Wu_enc, dWu_enc, mWu_enc, vWu_enc),\n",
        "        (Wr_enc, dWr_enc, mWr_enc, vWr_enc),\n",
        "        (Wh_enc, dWh_enc, mWh_enc, vWh_enc),\n",
        "\n",
        "        # Attention\n",
        "        (Wa, dWa, mWa, vWa),\n",
        "        (Ua, dUa, mUa, vUa),\n",
        "        (va, dva, mva, vva),\n",
        "\n",
        "        # Bridge\n",
        "        (W_bridge, dW_bridge, mW_bridge, vW_bridge),\n",
        "\n",
        "        # Decoder\n",
        "        (Wu_dec, dWu_dec, mWu_dec, vWu_dec),\n",
        "        (Wr_dec, dWr_dec, mWr_dec, vWr_dec),\n",
        "        (Wh_dec, dWh_dec, mWh_dec, vWh_dec),\n",
        "\n",
        "        # Output\n",
        "        (Wy, dWy, mWy, vWy),\n",
        "\n",
        "        # Biases - Encoder\n",
        "        (bu_enc, dbu_enc, mbu_enc, vbu_enc),\n",
        "        (br_enc, dbr_enc, mbr_enc, vbr_enc),\n",
        "        (bh_enc, dbh_enc, mbh_enc, vbh_enc),\n",
        "\n",
        "        # Biases - Bridge\n",
        "        (b_bridge, db_bridge, mb_bridge, vb_bridge),\n",
        "\n",
        "        # Biases - Decoder\n",
        "        (bu_dec, dbu_dec, mbu_dec, vbu_dec),\n",
        "        (br_dec, dbr_dec, mbr_dec, vbr_dec),\n",
        "        (bh_dec, dbh_dec, mbh_dec, vbh_dec),\n",
        "        (by, dby, mby, vby)\n",
        "    ]\n",
        "\n",
        "    updated_params = []\n",
        "\n",
        "    for param, grad, m, v in params:\n",
        "        m = beta1 * m + (1 - beta1) * grad\n",
        "        v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
        "\n",
        "        m_corrected = m / (1 - beta1 ** t_adam)\n",
        "        v_corrected = v / (1 - beta2 ** t_adam)\n",
        "\n",
        "        param = param - learning_rate * m_corrected / (np.sqrt(v_corrected) + epsilon)\n",
        "        updated_params.append((param, m, v))\n",
        "\n",
        "    # Unpack and Update Globals\n",
        "    (Wemb, mWemb, vWemb) = updated_params[0]\n",
        "\n",
        "    (Wu_enc, mWu_enc, vWu_enc) = updated_params[1]\n",
        "    (Wr_enc, mWr_enc, vWr_enc) = updated_params[2]\n",
        "    (Wh_enc, mWh_enc, vWh_enc) = updated_params[3]\n",
        "\n",
        "    (Wa, mWa, vWa) = updated_params[4]\n",
        "    (Ua, mUa, vUa) = updated_params[5]\n",
        "    (va, mva, vva) = updated_params[6]\n",
        "\n",
        "    (W_bridge, mW_bridge, vW_bridge) = updated_params[7]\n",
        "\n",
        "    (Wu_dec, mWu_dec, vWu_dec) = updated_params[8]\n",
        "    (Wr_dec, mWr_dec, vWr_dec) = updated_params[9]\n",
        "    (Wh_dec, mWh_dec, vWh_dec) = updated_params[10]\n",
        "    (Wy, mWy, vWy) = updated_params[11]\n",
        "\n",
        "    (bu_enc, mbu_enc, vbu_enc) = updated_params[12]\n",
        "    (br_enc, mbr_enc, vbr_enc) = updated_params[13]\n",
        "    (bh_enc, mbh_enc, vbh_enc) = updated_params[14]\n",
        "\n",
        "    (b_bridge, mb_bridge, vb_bridge) = updated_params[15]\n",
        "\n",
        "    (bu_dec, mbu_dec, vbu_dec) = updated_params[16]\n",
        "    (br_dec, mbr_dec, vbr_dec) = updated_params[17]\n",
        "    (bh_dec, mbh_dec, vbh_dec) = updated_params[18]\n",
        "    (by, mby, vby) = updated_params[19]"
      ],
      "metadata": {
        "id": "wSGIUqZsMU0E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __TRAIN MODEL__\n"
      ],
      "metadata": {
        "id": "hpHLQqh7XFil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(pairs, num_iterations=1000, print_every=100):\n",
        "    \"\"\"\n",
        "    Train the Encoder-Decoder Model with Bahdanau Attention\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    print_loss_total = 0\n",
        "\n",
        "    for iter in range(1, num_iterations + 1):\n",
        "        training_pair = random.choice(pairs)\n",
        "        src_inputs = training_pair['src']\n",
        "        dec_inputs = training_pair['dec_input']\n",
        "        dec_targets = training_pair['dec_target']\n",
        "\n",
        "        # Forward Pass\n",
        "        loss, enc_cache, bridge_cache, dec_cache, attn_cache = forward(src_inputs, dec_inputs, dec_targets)\n",
        "\n",
        "        # Backward Pass\n",
        "        grads = backward(src_inputs, dec_inputs, dec_targets,\n",
        "                         enc_cache, bridge_cache, dec_cache, attn_cache)\n",
        "\n",
        "        # Update Parameters\n",
        "        update_parameters(grads, lr)\n",
        "\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(f\"Iteration {iter} | Loss: {print_loss_avg:.4f}\")"
      ],
      "metadata": {
        "id": "HvrBIPp3XAt-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __GENERATE TEXT__"
      ],
      "metadata": {
        "id": "j4GOFoOuYzvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(source_sentence, max_len=25):\n",
        "    \"\"\"\n",
        "    Generate a response/next sentence using Bahdanau Attention.\n",
        "    \"\"\"\n",
        "    source_tokens = re.findall(r\"\\w+|[.,!?'\\\";:]\", source_sentence.lower())\n",
        "    src_indices = [word_to_ix.get(w, word_to_ix[UNK_TOKEN]) for w in source_tokens]\n",
        "\n",
        "    # ENCODER PASS\n",
        "    enc_ht = {}\n",
        "    h_enc = np.zeros((hidden_size, 1))\n",
        "    enc_ht[-1] = h_enc\n",
        "    for t, word_idx in enumerate(src_indices):\n",
        "        _, _, _, _, h_enc = encoder_step(enc_ht[t-1], word_idx)\n",
        "        enc_ht[t] = h_enc\n",
        "\n",
        "    # Stack hidden states for Attention (H, Seq_Len)\n",
        "    enc_list = [enc_ht[t] for t in range(len(src_indices))]\n",
        "    enc_matrix = np.concatenate(enc_list, axis=1)\n",
        "\n",
        "    # BRIDGE\n",
        "    # Initialize Decoder State\n",
        "    h_enc_final = enc_ht[len(src_indices) - 1]\n",
        "    bridge_z = np.dot(W_bridge, h_enc_final) + b_bridge\n",
        "    h_dec = np.tanh(bridge_z)\n",
        "\n",
        "    # DECODER GENERATION\n",
        "    curr_word_idx = word_to_ix[SOS_TOKEN]\n",
        "    generated_words = []\n",
        "    attention_weights = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Calculate Attention\n",
        "        context, alpha, _ = calculate_attention(h_dec, enc_matrix)\n",
        "        attention_weights.append(alpha.flatten())\n",
        "        # Decoder Step\n",
        "        _, _, _, _, h_dec, yt = decoder_step(h_dec, curr_word_idx, context)\n",
        "        prob = softmax(yt)\n",
        "        next_word_idx = np.argmax(prob)\n",
        "        next_word = ix_to_word[next_word_idx]\n",
        "        if next_word == EOS_TOKEN:\n",
        "            break\n",
        "        generated_words.append(next_word)\n",
        "        curr_word_idx = next_word_idx\n",
        "\n",
        "    return generated_words, np.array(attention_weights), source_tokens\n",
        "\n",
        "def plot_attention(source_words, predicted_words, attention_matrix):\n",
        "    \"\"\"\n",
        "    Visualizes the Bahdanau Attention weights without warnings.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    cax = ax.matshow(attention_matrix, cmap='viridis')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(source_words)))\n",
        "    ax.set_yticks(np.arange(len(predicted_words)))\n",
        "    ax.set_xticklabels(source_words, rotation=90)\n",
        "    ax.set_yticklabels(predicted_words)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ldl7q4JsYWJs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __RUN TRAINING__"
      ],
      "metadata": {
        "id": "1y0M3vMIZcjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(training_pairs, num_iterations=5000, print_every=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjfsldMiZVna",
        "outputId": "b2adad5f-9326-437e-edad-bac15eedd157"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 500 | Loss: 19.4348\n",
            "Iteration 1000 | Loss: 11.0874\n",
            "Iteration 1500 | Loss: 6.4199\n",
            "Iteration 2000 | Loss: 4.1787\n",
            "Iteration 2500 | Loss: 3.0990\n",
            "Iteration 3000 | Loss: 2.4653\n",
            "Iteration 3500 | Loss: 1.9750\n",
            "Iteration 4000 | Loss: 1.5443\n",
            "Iteration 4500 | Loss: 1.1016\n",
            "Iteration 5000 | Loss: 1.0349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __TEST__"
      ],
      "metadata": {
        "id": "jhx3NWCEtl0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"The water level was low\",\n",
        "    \"The crow thought for a moment\",\n",
        "]\n",
        "for sent in test_sentences:\n",
        "    response, _, _ = predict(sent)\n",
        "    print(f\"Input:  {sent}\")\n",
        "    print(f\"Output: {\" \".join(response)}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_1JWyvyZi7B",
        "outputId": "2f6dc018-5dfe-447f-a793-979c1beb3a27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  The water level was low\n",
            "Output: the water was at the bottom .\n",
            "------------------------------\n",
            "Input:  The crow thought for a moment\n",
            "Output: he threw too very dry .\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __PLOT ALIGNMENT__"
      ],
      "metadata": {
        "id": "uMRbEnw0lLRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"The water level was low\"\n",
        "gen_words, attn_matrix, src_words = predict(test_sentence)\n",
        "plot_attention(src_words, gen_words, attn_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "THND6vDljqyS",
        "outputId": "d3680bb0-48ad-4557-eff5-1ac4dd493175"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SUMMARY**\n",
        "\n",
        "This implementation demonstrates **Bahdanau Attention**, the first successful attention mechanism for neural machine translation. The key insight is allowing the decoder to dynamically focus on different parts of the source sentence at each generation step, eliminating the fixed bottleneck of standard encoder-decoder models.\n",
        "\n",
        "### **Key Achievements in This Notebook:**\n",
        "1. **Additive Attention**: Implemented the original Bahdanau scoring function\n",
        "2. **Complete BPTT**: Correctly backpropagate through attention, GRUs, and bridge\n",
        "3. **Attention Visualization**: Plotted alignment matrices showing which source words influence each generated word\n",
        "\n",
        "### **Key Points:**\n",
        "- **Attention solves the bottleneck problem**: Performance doesn't degrade on longer sentences\n",
        "- **Dynamic context is powerful**: The model learns meaningful alignments without explicit supervision\n",
        "- **Gradient flow matters**: Proper clipping and initialization are critical for attention stability\n",
        "- **Attention is interpretable**: We can visualize exactly what the model is \"looking at\"\n",
        "\n",
        "### **Limitations of This Approach:**\n",
        "- **Computational cost**: Attention requires $O(T_{enc} \\times T_{dec})$ operations\n",
        "- **Recurrence**: Still processes sequentially, limiting parallelization\n",
        "- **Fixed direction**: Encoder must process left-to-right before decoder starts\n",
        "\n",
        "### **Historical Context:**\n",
        "This architecture (Bahdanau et al., 2014) was revolutionary, significantly outperforming previous seq2seq models. However, it was later superseded by **Transformers** (Vaswani et al., 2017), which:\n",
        "- Replace RNNs with **self-attention** entirely\n",
        "- Process sequences in parallel\n",
        "- Stack multiple attention heads\n",
        "- Scale to much larger datasets\n",
        "\n",
        "### **Further Reading:**\n",
        "\n",
        "**Attention Papers:**\n",
        "1. [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) — Bahdanau et al. (2014)  \n",
        "   *The paper this notebook implements*\n",
        "\n",
        "2. [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) — Luong et al. (2015)  \n",
        "   *Alternative attention mechanisms (multiplicative, global vs. local)*\n",
        "\n",
        "**Foundation Papers:**\n",
        "\n",
        "3. [Learning Phrase Representations using RNN Encoder–Decoder](https://arxiv.org/abs/1406.1078) — Cho et al. (2014)  \n",
        "   *Introduced GRU and encoder-decoder architecture*\n",
        "\n",
        "4. [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) — Sutskever et al. (2014)  \n",
        "   *LSTM-based seq2seq without attention*\n",
        "\n",
        "**Modern Architectures:**\n",
        "\n",
        "5. [Attention Is All You Need](https://arxiv.org/abs/1706.03762) — Vaswani et al. (2017)  \n",
        "   *Transformers — the architecture that powers GPT, BERT, and modern LLMs*\n",
        "\n",
        "6. [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) — Jay Alammar  \n",
        "   *Excellent visual guide to understanding Transformers*\n"
      ],
      "metadata": {
        "id": "emJt2n4kukCR"
      }
    }
  ]
}